{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee9c06-d697-4ac6-aeda-5b3b450cad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd72c0ff-8e2f-4c2c-8b3f-c75547ea8258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1389 entries, 0 to 1388\n",
      "Data columns (total 13 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   modified Zurich class            1389 non-null   object\n",
      " 1   largest spot size                1389 non-null   object\n",
      " 2   spot distribution                1389 non-null   object\n",
      " 3   activity                         1389 non-null   int64 \n",
      " 4   evolution                        1389 non-null   int64 \n",
      " 5   previous 24 hour flare activity  1389 non-null   int64 \n",
      " 6   historically-complex             1389 non-null   int64 \n",
      " 7   became complex on this pass      1389 non-null   int64 \n",
      " 8   area                             1389 non-null   int64 \n",
      " 9   area of largest spot             1389 non-null   int64 \n",
      " 10  common flares                    1389 non-null   int64 \n",
      " 11  moderate flares                  1389 non-null   int64 \n",
      " 12  severe flares                    1389 non-null   int64 \n",
      "dtypes: int64(10), object(3)\n",
      "memory usage: 141.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>evolution</th>\n",
       "      <th>previous 24 hour flare activity</th>\n",
       "      <th>historically-complex</th>\n",
       "      <th>became complex on this pass</th>\n",
       "      <th>area</th>\n",
       "      <th>area of largest spot</th>\n",
       "      <th>common flares</th>\n",
       "      <th>moderate flares</th>\n",
       "      <th>severe flares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1389.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.150468</td>\n",
       "      <td>2.421166</td>\n",
       "      <td>1.089993</td>\n",
       "      <td>1.395968</td>\n",
       "      <td>1.892009</td>\n",
       "      <td>1.025918</td>\n",
       "      <td>1.175666</td>\n",
       "      <td>0.261339</td>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.009359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.357658</td>\n",
       "      <td>0.617129</td>\n",
       "      <td>0.403292</td>\n",
       "      <td>0.489234</td>\n",
       "      <td>0.310481</td>\n",
       "      <td>0.158948</td>\n",
       "      <td>0.380673</td>\n",
       "      <td>0.760201</td>\n",
       "      <td>0.353695</td>\n",
       "      <td>0.103534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          activity    evolution  previous 24 hour flare activity  \\\n",
       "count  1389.000000  1389.000000                      1389.000000   \n",
       "mean      1.150468     2.421166                         1.089993   \n",
       "std       0.357658     0.617129                         0.403292   \n",
       "min       1.000000     1.000000                         1.000000   \n",
       "25%       1.000000     2.000000                         1.000000   \n",
       "50%       1.000000     2.000000                         1.000000   \n",
       "75%       1.000000     3.000000                         1.000000   \n",
       "max       2.000000     3.000000                         3.000000   \n",
       "\n",
       "       historically-complex  became complex on this pass         area  \\\n",
       "count           1389.000000                  1389.000000  1389.000000   \n",
       "mean               1.395968                     1.892009     1.025918   \n",
       "std                0.489234                     0.310481     0.158948   \n",
       "min                1.000000                     1.000000     1.000000   \n",
       "25%                1.000000                     2.000000     1.000000   \n",
       "50%                1.000000                     2.000000     1.000000   \n",
       "75%                2.000000                     2.000000     1.000000   \n",
       "max                2.000000                     2.000000     2.000000   \n",
       "\n",
       "       area of largest spot  common flares  moderate flares  severe flares  \n",
       "count           1389.000000    1389.000000      1389.000000    1389.000000  \n",
       "mean               1.175666       0.261339         0.067675       0.009359  \n",
       "std                0.380673       0.760201         0.353695       0.103534  \n",
       "min                1.000000       0.000000         0.000000       0.000000  \n",
       "25%                1.000000       0.000000         0.000000       0.000000  \n",
       "50%                1.000000       0.000000         0.000000       0.000000  \n",
       "75%                1.000000       0.000000         0.000000       0.000000  \n",
       "max                2.000000       8.000000         5.000000       2.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/rifah/Downloads/data.csv\")\n",
    "\n",
    "df.info()\n",
    "df.shape\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96cd7d26-13cb-4541-b033-82406248662e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modified Zurich class              object\n",
       "largest spot size                  object\n",
       "spot distribution                  object\n",
       "activity                            int64\n",
       "evolution                           int64\n",
       "previous 24 hour flare activity     int64\n",
       "historically-complex                int64\n",
       "became complex on this pass         int64\n",
       "area                                int64\n",
       "area of largest spot                int64\n",
       "common flares                       int64\n",
       "moderate flares                     int64\n",
       "severe flares                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "068a7c2a-7bed-42c0-bbc7-bc21d97d1c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modified Zurich class</th>\n",
       "      <th>largest spot size</th>\n",
       "      <th>spot distribution</th>\n",
       "      <th>activity</th>\n",
       "      <th>evolution</th>\n",
       "      <th>previous 24 hour flare activity</th>\n",
       "      <th>historically-complex</th>\n",
       "      <th>became complex on this pass</th>\n",
       "      <th>area</th>\n",
       "      <th>area of largest spot</th>\n",
       "      <th>common flares</th>\n",
       "      <th>moderate flares</th>\n",
       "      <th>severe flares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>S</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>S</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modified Zurich class largest spot size spot distribution  activity  \\\n",
       "0                     C                 S                 O         1   \n",
       "1                     D                 S                 O         1   \n",
       "2                     C                 S                 O         1   \n",
       "3                     D                 S                 O         1   \n",
       "4                     D                 A                 O         1   \n",
       "\n",
       "   evolution  previous 24 hour flare activity  historically-complex  \\\n",
       "0          2                                1                     1   \n",
       "1          3                                1                     1   \n",
       "2          3                                1                     1   \n",
       "3          3                                1                     1   \n",
       "4          3                                1                     1   \n",
       "\n",
       "   became complex on this pass  area  area of largest spot  common flares  \\\n",
       "0                            2     1                     2              0   \n",
       "1                            2     1                     2              0   \n",
       "2                            2     1                     1              0   \n",
       "3                            2     1                     2              0   \n",
       "4                            2     1                     2              0   \n",
       "\n",
       "   moderate flares  severe flares  \n",
       "0                0              0  \n",
       "1                0              0  \n",
       "2                0              0  \n",
       "3                0              0  \n",
       "4                0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34cdd86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modified Zurich class</th>\n",
       "      <th>largest spot size</th>\n",
       "      <th>spot distribution</th>\n",
       "      <th>activity</th>\n",
       "      <th>evolution</th>\n",
       "      <th>previous 24 hour flare activity</th>\n",
       "      <th>historically-complex</th>\n",
       "      <th>became complex on this pass</th>\n",
       "      <th>area</th>\n",
       "      <th>area of largest spot</th>\n",
       "      <th>common flares</th>\n",
       "      <th>moderate flares</th>\n",
       "      <th>severe flares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>S</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>H</td>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>H</td>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     modified Zurich class largest spot size spot distribution  activity  \\\n",
       "0                        C                 S                 O         1   \n",
       "1                        D                 S                 O         1   \n",
       "2                        C                 S                 O         1   \n",
       "4                        D                 A                 O         1   \n",
       "5                        D                 A                 O         1   \n",
       "...                    ...               ...               ...       ...   \n",
       "1355                     D                 H                 O         1   \n",
       "1357                     D                 A                 I         2   \n",
       "1369                     E                 A                 O         1   \n",
       "1370                     H                 S                 X         1   \n",
       "1381                     H                 S                 X         1   \n",
       "\n",
       "      evolution  previous 24 hour flare activity  historically-complex  \\\n",
       "0             2                                1                     1   \n",
       "1             3                                1                     1   \n",
       "2             3                                1                     1   \n",
       "4             3                                1                     1   \n",
       "5             2                                1                     1   \n",
       "...         ...                              ...                   ...   \n",
       "1355          2                                1                     2   \n",
       "1357          3                                2                     1   \n",
       "1369          2                                1                     2   \n",
       "1370          3                                1                     1   \n",
       "1381          2                                2                     2   \n",
       "\n",
       "      became complex on this pass  area  area of largest spot  common flares  \\\n",
       "0                               2     1                     2              0   \n",
       "1                               2     1                     2              0   \n",
       "2                               2     1                     1              0   \n",
       "4                               2     1                     2              0   \n",
       "5                               2     1                     2              0   \n",
       "...                           ...   ...                   ...            ...   \n",
       "1355                            2     1                     1              0   \n",
       "1357                            2     1                     1              0   \n",
       "1369                            2     1                     1              4   \n",
       "1370                            1     1                     1              1   \n",
       "1381                            2     1                     1              0   \n",
       "\n",
       "      moderate flares  severe flares  \n",
       "0                   0              0  \n",
       "1                   0              0  \n",
       "2                   0              0  \n",
       "4                   0              0  \n",
       "5                   0              0  \n",
       "...               ...            ...  \n",
       "1355                0              0  \n",
       "1357                0              0  \n",
       "1369                1              0  \n",
       "1370                0              0  \n",
       "1381                0              0  \n",
       "\n",
       "[527 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = df.drop_duplicates()\n",
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5294670a-af32-4342-b40a-58a4f5ffb95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modified Zurich class              6\n",
       "largest spot size                  6\n",
       "spot distribution                  4\n",
       "activity                           2\n",
       "evolution                          3\n",
       "previous 24 hour flare activity    3\n",
       "historically-complex               2\n",
       "became complex on this pass        2\n",
       "area                               2\n",
       "area of largest spot               2\n",
       "common flares                      8\n",
       "moderate flares                    6\n",
       "severe flares                      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b58f2d-1ba1-4ed3-aba9-5cb8fe420947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified Zurich class\n",
      "D    164\n",
      "C    105\n",
      "E     91\n",
      "H     87\n",
      "F     46\n",
      "B     34\n",
      "Name: count, dtype: int64\n",
      "largest spot size\n",
      "S    156\n",
      "A    153\n",
      "K     83\n",
      "R     73\n",
      "X     32\n",
      "H     30\n",
      "Name: count, dtype: int64\n",
      "spot distribution\n",
      "O    196\n",
      "I    194\n",
      "X     87\n",
      "C     50\n",
      "Name: count, dtype: int64\n",
      "activity\n",
      "1    356\n",
      "2    171\n",
      "Name: count, dtype: int64\n",
      "evolution\n",
      "3    256\n",
      "2    226\n",
      "1     45\n",
      "Name: count, dtype: int64\n",
      "previous 24 hour flare activity\n",
      "1    463\n",
      "3     52\n",
      "2     12\n",
      "Name: count, dtype: int64\n",
      "historically-complex\n",
      "2    309\n",
      "1    218\n",
      "Name: count, dtype: int64\n",
      "became complex on this pass\n",
      "2    498\n",
      "1     29\n",
      "Name: count, dtype: int64\n",
      "area\n",
      "1    493\n",
      "2     34\n",
      "Name: count, dtype: int64\n",
      "area of largest spot\n",
      "1    373\n",
      "2    154\n",
      "Name: count, dtype: int64\n",
      "common flares\n",
      "0    347\n",
      "1    105\n",
      "2     39\n",
      "3     19\n",
      "4      9\n",
      "5      4\n",
      "6      3\n",
      "8      1\n",
      "Name: count, dtype: int64\n",
      "moderate flares\n",
      "0    461\n",
      "1     51\n",
      "2      9\n",
      "4      3\n",
      "3      2\n",
      "5      1\n",
      "Name: count, dtype: int64\n",
      "severe flares\n",
      "0    515\n",
      "1     11\n",
      "2      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = ([\"modified Zurich class\",'largest spot size', 'spot distribution', 'activity', 'evolution',\t'previous 24 hour flare activity', 'historically-complex', 'became complex on this pass' ,'area','area of largest spot','common flares', 'moderate flares', 'severe flares'])\n",
    "for col in cols:\n",
    "    \n",
    "    print(df[col].value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d689a54b-2613-4bbd-b2ae-63422f20a4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>evolution</th>\n",
       "      <th>previous 24 hour flare activity</th>\n",
       "      <th>historically-complex</th>\n",
       "      <th>became complex on this pass</th>\n",
       "      <th>area</th>\n",
       "      <th>area of largest spot</th>\n",
       "      <th>common flares</th>\n",
       "      <th>moderate flares</th>\n",
       "      <th>severe flares</th>\n",
       "      <th>modified Zurich class_B</th>\n",
       "      <th>modified Zurich class_C</th>\n",
       "      <th>modified Zurich class_D</th>\n",
       "      <th>modified Zurich class_E</th>\n",
       "      <th>modified Zurich class_F</th>\n",
       "      <th>modified Zurich class_H</th>\n",
       "      <th>largest spot size_A</th>\n",
       "      <th>largest spot size_H</th>\n",
       "      <th>largest spot size_K</th>\n",
       "      <th>largest spot size_R</th>\n",
       "      <th>largest spot size_S</th>\n",
       "      <th>largest spot size_X</th>\n",
       "      <th>spot distribution_C</th>\n",
       "      <th>spot distribution_I</th>\n",
       "      <th>spot distribution_O</th>\n",
       "      <th>spot distribution_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      activity  evolution  previous 24 hour flare activity  \\\n",
       "0            1          2                                1   \n",
       "1            1          3                                1   \n",
       "2            1          3                                1   \n",
       "4            1          3                                1   \n",
       "5            1          2                                1   \n",
       "...        ...        ...                              ...   \n",
       "1355         1          2                                1   \n",
       "1357         2          3                                2   \n",
       "1369         1          2                                1   \n",
       "1370         1          3                                1   \n",
       "1381         1          2                                2   \n",
       "\n",
       "      historically-complex  became complex on this pass  area  \\\n",
       "0                        1                            2     1   \n",
       "1                        1                            2     1   \n",
       "2                        1                            2     1   \n",
       "4                        1                            2     1   \n",
       "5                        1                            2     1   \n",
       "...                    ...                          ...   ...   \n",
       "1355                     2                            2     1   \n",
       "1357                     1                            2     1   \n",
       "1369                     2                            2     1   \n",
       "1370                     1                            1     1   \n",
       "1381                     2                            2     1   \n",
       "\n",
       "      area of largest spot  common flares  moderate flares  severe flares  \\\n",
       "0                        2              0                0              0   \n",
       "1                        2              0                0              0   \n",
       "2                        1              0                0              0   \n",
       "4                        2              0                0              0   \n",
       "5                        2              0                0              0   \n",
       "...                    ...            ...              ...            ...   \n",
       "1355                     1              0                0              0   \n",
       "1357                     1              0                0              0   \n",
       "1369                     1              4                1              0   \n",
       "1370                     1              1                0              0   \n",
       "1381                     1              0                0              0   \n",
       "\n",
       "      modified Zurich class_B  modified Zurich class_C  \\\n",
       "0                       False                     True   \n",
       "1                       False                    False   \n",
       "2                       False                     True   \n",
       "4                       False                    False   \n",
       "5                       False                    False   \n",
       "...                       ...                      ...   \n",
       "1355                    False                    False   \n",
       "1357                    False                    False   \n",
       "1369                    False                    False   \n",
       "1370                    False                    False   \n",
       "1381                    False                    False   \n",
       "\n",
       "      modified Zurich class_D  modified Zurich class_E  \\\n",
       "0                       False                    False   \n",
       "1                        True                    False   \n",
       "2                       False                    False   \n",
       "4                        True                    False   \n",
       "5                        True                    False   \n",
       "...                       ...                      ...   \n",
       "1355                     True                    False   \n",
       "1357                     True                    False   \n",
       "1369                    False                     True   \n",
       "1370                    False                    False   \n",
       "1381                    False                    False   \n",
       "\n",
       "      modified Zurich class_F  modified Zurich class_H  largest spot size_A  \\\n",
       "0                       False                    False                False   \n",
       "1                       False                    False                False   \n",
       "2                       False                    False                False   \n",
       "4                       False                    False                 True   \n",
       "5                       False                    False                 True   \n",
       "...                       ...                      ...                  ...   \n",
       "1355                    False                    False                False   \n",
       "1357                    False                    False                 True   \n",
       "1369                    False                    False                 True   \n",
       "1370                    False                     True                False   \n",
       "1381                    False                     True                False   \n",
       "\n",
       "      largest spot size_H  largest spot size_K  largest spot size_R  \\\n",
       "0                   False                False                False   \n",
       "1                   False                False                False   \n",
       "2                   False                False                False   \n",
       "4                   False                False                False   \n",
       "5                   False                False                False   \n",
       "...                   ...                  ...                  ...   \n",
       "1355                 True                False                False   \n",
       "1357                False                False                False   \n",
       "1369                False                False                False   \n",
       "1370                False                False                False   \n",
       "1381                False                False                False   \n",
       "\n",
       "      largest spot size_S  largest spot size_X  spot distribution_C  \\\n",
       "0                    True                False                False   \n",
       "1                    True                False                False   \n",
       "2                    True                False                False   \n",
       "4                   False                False                False   \n",
       "5                   False                False                False   \n",
       "...                   ...                  ...                  ...   \n",
       "1355                False                False                False   \n",
       "1357                False                False                False   \n",
       "1369                False                False                False   \n",
       "1370                 True                False                False   \n",
       "1381                 True                False                False   \n",
       "\n",
       "      spot distribution_I  spot distribution_O  spot distribution_X  \n",
       "0                   False                 True                False  \n",
       "1                   False                 True                False  \n",
       "2                   False                 True                False  \n",
       "4                   False                 True                False  \n",
       "5                   False                 True                False  \n",
       "...                   ...                  ...                  ...  \n",
       "1355                False                 True                False  \n",
       "1357                 True                False                False  \n",
       "1369                False                 True                False  \n",
       "1370                False                False                 True  \n",
       "1381                False                False                 True  \n",
       "\n",
       "[527 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.get_dummies(df, columns=[\"modified Zurich class\",'largest spot size', 'spot distribution'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb630422-3e48-4197-9305-842ea7c77165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 540 candidates, totalling 2160 fits\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.334, test=-0.460) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.290, test=-0.580) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.286, test=-0.607) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.283, test=-0.617) total time=   0.1s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.338, test=-0.449) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.291, test=-0.596) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.288, test=-0.600) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.282, test=-0.601) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.335, test=-0.443) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.292, test=-0.575) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.287, test=-0.590) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.284, test=-0.607) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.333, test=-0.450) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.289, test=-0.583) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.285, test=-0.594) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.281, test=-0.611) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.331, test=-0.444) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.288, test=-0.587) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.285, test=-0.599) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.283, test=-0.606) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.375, test=-0.423) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.330, test=-0.575) total time=   0.1s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.331, test=-0.552) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.321, test=-0.585) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.375, test=-0.418) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.327, test=-0.570) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.329, test=-0.555) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.318, test=-0.577) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.371, test=-0.419) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.331, test=-0.560) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.331, test=-0.550) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.317, test=-0.591) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.371, test=-0.422) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.327, test=-0.561) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.332, test=-0.550) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.317, test=-0.589) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.374, test=-0.417) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.325, test=-0.563) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.326, test=-0.551) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.318, test=-0.583) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.397, test=-0.412) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.352, test=-0.558) total time=   0.1s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.357, test=-0.524) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.341, test=-0.601) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.401, test=-0.397) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.353, test=-0.551) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.355, test=-0.528) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.340, test=-0.580) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.400, test=-0.401) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.350, test=-0.554) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.357, test=-0.529) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.343, test=-0.579) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.396, test=-0.401) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.350, test=-0.547) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.352, test=-0.527) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.340, test=-0.577) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.396, test=-0.406) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.351, test=-0.549) total time=   0.5s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.357, test=-0.527) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.341, test=-0.578) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.372, test=-0.414) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.337, test=-0.564) total time=   0.1s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.322, test=-0.570) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.318, test=-0.608) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.373, test=-0.410) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.333, test=-0.553) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.325, test=-0.565) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.315, test=-0.601) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.370, test=-0.414) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.332, test=-0.559) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.322, test=-0.575) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.317, test=-0.600) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.368, test=-0.416) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.331, test=-0.560) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.322, test=-0.566) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.317, test=-0.605) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.417) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.331, test=-0.563) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.325, test=-0.562) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.316, test=-0.601) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.393, test=-0.400) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.353, test=-0.548) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.357, test=-0.545) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.336, test=-0.588) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.393, test=-0.394) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.355, test=-0.539) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.349, test=-0.544) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.334, test=-0.595) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.391, test=-0.399) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.354, test=-0.538) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.350, test=-0.533) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.337, test=-0.585) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.388, test=-0.401) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.355, test=-0.544) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.351, test=-0.540) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.337, test=-0.595) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.389, test=-0.407) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.354, test=-0.548) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.349, test=-0.536) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.338, test=-0.588) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.407, test=-0.398) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.373, test=-0.535) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.374, test=-0.522) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.354, test=-0.584) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.408, test=-0.398) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.373, test=-0.528) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.371, test=-0.533) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.354, test=-0.578) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.405, test=-0.391) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.372, test=-0.539) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.367, test=-0.522) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.353, test=-0.584) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.409, test=-0.385) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.371, test=-0.538) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.369, test=-0.523) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.354, test=-0.581) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.408, test=-0.392) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.371, test=-0.536) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.371, test=-0.515) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.353, test=-0.581) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.405, test=-0.406) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.369, test=-0.544) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.362, test=-0.540) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.351, test=-0.593) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.404, test=-0.394) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.370, test=-0.544) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.369, test=-0.532) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.354, test=-0.592) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.404, test=-0.397) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.369, test=-0.532) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.367, test=-0.516) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.351, test=-0.592) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.404, test=-0.394) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.369, test=-0.538) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.367, test=-0.518) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.351, test=-0.596) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.404, test=-0.388) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.535) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.367, test=-0.522) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.352, test=-0.589) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.409, test=-0.384) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.371, test=-0.551) total time=   0.1s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.367, test=-0.525) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.352, test=-0.580) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.405, test=-0.390) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.370, test=-0.533) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.368, test=-0.531) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.353, test=-0.593) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.403, test=-0.396) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.369, test=-0.534) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.367, test=-0.530) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.352, test=-0.593) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.407, test=-0.386) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.367, test=-0.535) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.364, test=-0.522) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.353, test=-0.590) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.407, test=-0.389) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.368, test=-0.540) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.367, test=-0.524) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.353, test=-0.590) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.416, test=-0.386) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.380, test=-0.534) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.378, test=-0.510) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.364, test=-0.584) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.414, test=-0.386) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.380, test=-0.531) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.381, test=-0.517) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.360, test=-0.585) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.414, test=-0.385) total time=   0.5s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.380, test=-0.533) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.379, test=-0.507) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.361, test=-0.580) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.416, test=-0.380) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.378, test=-0.536) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.378, test=-0.512) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.362, test=-0.587) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.415, test=-0.387) total time=   0.5s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.380, test=-0.532) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.379, test=-0.513) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.364, test=-0.581) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.325, test=-0.454) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.285, test=-0.590) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.281, test=-0.612) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.276, test=-0.614) total time=   0.1s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.325, test=-0.464) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.282, test=-0.582) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.283, test=-0.612) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.279, test=-0.619) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.321, test=-0.464) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.278, test=-0.597) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.279, test=-0.607) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.279, test=-0.612) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.320, test=-0.465) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.282, test=-0.596) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.278, test=-0.600) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.278, test=-0.608) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.318, test=-0.469) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.282, test=-0.595) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.275, test=-0.611) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.277, test=-0.605) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.371, test=-0.435) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.329, test=-0.569) total time=   0.1s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.331, test=-0.552) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.316, test=-0.586) total time=   0.1s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.369, test=-0.419) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.323, test=-0.562) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.331, test=-0.544) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.318, test=-0.579) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.368, test=-0.422) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.325, test=-0.569) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.326, test=-0.552) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.319, test=-0.588) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.367, test=-0.427) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.321, test=-0.568) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.325, test=-0.550) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.316, test=-0.584) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.368, test=-0.423) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.324, test=-0.565) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.329, test=-0.545) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.317, test=-0.591) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.397, test=-0.388) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.353, test=-0.539) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.356, test=-0.530) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.339, test=-0.587) total time=   0.1s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.396, test=-0.396) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.349, test=-0.546) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.359, test=-0.521) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.339, test=-0.576) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.397, test=-0.399) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.351, test=-0.543) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.354, test=-0.518) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.341, test=-0.578) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.394, test=-0.409) total time=   0.5s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.347, test=-0.550) total time=   0.5s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.357, test=-0.522) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.338, test=-0.576) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.392, test=-0.409) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.349, test=-0.550) total time=   0.5s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.356, test=-0.524) total time=   0.6s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.341, test=-0.583) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.365, test=-0.411) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.331, test=-0.574) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.321, test=-0.559) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.312, test=-0.613) total time=   0.1s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.365, test=-0.417) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.332, test=-0.568) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.316, test=-0.585) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.315, test=-0.594) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.364, test=-0.412) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.330, test=-0.556) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.323, test=-0.555) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.315, test=-0.611) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.364, test=-0.420) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.330, test=-0.556) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.320, test=-0.565) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.317, test=-0.605) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.365, test=-0.418) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.328, test=-0.559) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.320, test=-0.563) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.318, test=-0.601) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.387, test=-0.408) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.354, test=-0.559) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.350, test=-0.540) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.338, test=-0.584) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.386, test=-0.412) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.356, test=-0.548) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.348, test=-0.541) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.339, test=-0.583) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.387, test=-0.407) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.353, test=-0.542) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.347, test=-0.533) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.337, test=-0.586) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.384, test=-0.411) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.353, test=-0.549) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.347, test=-0.543) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.338, test=-0.591) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.385, test=-0.406) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.352, test=-0.545) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.347, test=-0.547) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.336, test=-0.589) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.406, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.374, test=-0.552) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.371, test=-0.518) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.354, test=-0.583) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.407, test=-0.397) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.372, test=-0.537) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.370, test=-0.522) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.353, test=-0.581) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.405, test=-0.392) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.373, test=-0.539) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.367, test=-0.530) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.352, test=-0.578) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.405, test=-0.390) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.372, test=-0.536) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.370, test=-0.528) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.354, test=-0.575) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.406, test=-0.390) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.371, test=-0.536) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.367, test=-0.515) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.354, test=-0.581) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.401, test=-0.397) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.372, test=-0.541) total time=   0.1s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.365, test=-0.539) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.350, test=-0.587) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.402, test=-0.399) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.372, test=-0.537) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.363, test=-0.529) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.353, test=-0.591) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.401, test=-0.395) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.369, test=-0.541) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.365, test=-0.514) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.352, test=-0.588) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.402, test=-0.391) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.368, test=-0.534) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.367, test=-0.523) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.353, test=-0.588) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.402, test=-0.396) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.536) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.366, test=-0.530) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.352, test=-0.595) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.403, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.369, test=-0.534) total time=   0.1s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.366, test=-0.528) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.353, test=-0.587) total time=   0.1s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.401, test=-0.394) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.368, test=-0.541) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.365, test=-0.533) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.352, test=-0.589) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.403, test=-0.397) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.370, test=-0.540) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.363, test=-0.522) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.351, test=-0.594) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.403, test=-0.390) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.369, test=-0.542) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.366, test=-0.520) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.352, test=-0.587) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.404, test=-0.393) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.368, test=-0.538) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.366, test=-0.521) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.352, test=-0.581) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.414, test=-0.383) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.378, test=-0.539) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.381, test=-0.514) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.363, test=-0.581) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.412, test=-0.398) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.378, test=-0.536) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.380, test=-0.518) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.361, test=-0.583) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.414, test=-0.382) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.380, test=-0.530) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.378, test=-0.516) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.361, test=-0.581) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.416, test=-0.384) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.378, test=-0.533) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.381, test=-0.508) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.363, test=-0.583) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.416, test=-0.380) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.378, test=-0.535) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.378, test=-0.522) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.362, test=-0.588) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.327, test=-0.465) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.289, test=-0.594) total time=   0.1s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.277, test=-0.607) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.283, test=-0.606) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.323, test=-0.467) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.286, test=-0.587) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.281, test=-0.616) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.279, test=-0.596) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.320, test=-0.459) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.284, test=-0.592) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.281, test=-0.618) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.277, test=-0.614) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.322, test=-0.464) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.283, test=-0.594) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.280, test=-0.603) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.278, test=-0.621) total time=   0.6s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.321, test=-0.459) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.283, test=-0.590) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.277, test=-0.605) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.277, test=-0.610) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.369, test=-0.420) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.327, test=-0.553) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.330, test=-0.553) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.320, test=-0.592) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.369, test=-0.429) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.329, test=-0.561) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.329, test=-0.540) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.317, test=-0.585) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.369, test=-0.423) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.324, test=-0.565) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.323, test=-0.553) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.317, test=-0.594) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.367, test=-0.420) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.323, test=-0.567) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.324, test=-0.555) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.317, test=-0.587) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.367, test=-0.426) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.323, test=-0.563) total time=   0.5s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.323, test=-0.548) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.314, test=-0.594) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.396, test=-0.403) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.350, test=-0.546) total time=   0.1s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.354, test=-0.528) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.342, test=-0.579) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.395, test=-0.403) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.348, test=-0.556) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.355, test=-0.518) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.340, test=-0.567) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.395, test=-0.410) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.349, test=-0.542) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.351, test=-0.531) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.341, test=-0.585) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.395, test=-0.408) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.349, test=-0.555) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.355, test=-0.519) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.339, test=-0.577) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.396, test=-0.406) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.346, test=-0.557) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.355, test=-0.527) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.339, test=-0.581) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.367, test=-0.418) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.332, test=-0.561) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.319, test=-0.564) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.318, test=-0.603) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.360, test=-0.424) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.330, test=-0.560) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.321, test=-0.572) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.314, test=-0.605) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.364, test=-0.424) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.330, test=-0.565) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.318, test=-0.573) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.318, test=-0.613) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.362, test=-0.417) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.329, test=-0.560) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.317, test=-0.578) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.314, test=-0.598) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.366, test=-0.416) total time=   0.6s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.329, test=-0.557) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.318, test=-0.564) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.316, test=-0.601) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.392, test=-0.397) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.353, test=-0.543) total time=   0.1s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.348, test=-0.553) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.335, test=-0.595) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.388, test=-0.415) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.353, test=-0.537) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.349, test=-0.534) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.333, test=-0.587) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.387, test=-0.406) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.354, test=-0.542) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.345, test=-0.537) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.333, test=-0.598) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.389, test=-0.405) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.353, test=-0.552) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.348, test=-0.535) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.337, test=-0.585) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.386, test=-0.404) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.353, test=-0.541) total time=   0.5s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.346, test=-0.535) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.335, test=-0.594) total time=   0.5s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.410, test=-0.387) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.371, test=-0.537) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.369, test=-0.526) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.355, test=-0.585) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.410, test=-0.389) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.372, test=-0.539) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.369, test=-0.517) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.354, test=-0.582) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.405, test=-0.395) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.372, test=-0.534) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.371, test=-0.514) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.354, test=-0.581) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.406, test=-0.389) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.372, test=-0.534) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.369, test=-0.519) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.355, test=-0.580) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.407, test=-0.389) total time=   0.5s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.372, test=-0.531) total time=   0.5s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.512) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.353, test=-0.581) total time=   0.5s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.405, test=-0.381) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.369, test=-0.545) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.367, test=-0.525) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.353, test=-0.598) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.404, test=-0.389) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.370, test=-0.528) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.367, test=-0.524) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.352, test=-0.593) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.405, test=-0.400) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.370, test=-0.545) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.368, test=-0.526) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.351, test=-0.585) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.403, test=-0.387) total time=   0.7s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.369, test=-0.536) total time=   0.8s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.367, test=-0.518) total time=   0.7s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.352, test=-0.595) total time=   0.6s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.402, test=-0.390) total time=   0.6s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.368, test=-0.532) total time=   0.6s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.365, test=-0.519) total time=   0.8s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.352, test=-0.596) total time=   0.7s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.404, test=-0.395) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.369, test=-0.538) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.365, test=-0.522) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.351, test=-0.604) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.403, test=-0.399) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.371, test=-0.542) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.368, test=-0.523) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.352, test=-0.580) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.405, test=-0.401) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.367, test=-0.543) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.367, test=-0.521) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.352, test=-0.592) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.404, test=-0.392) total time=   0.5s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.368, test=-0.537) total time=   0.5s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.366, test=-0.525) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.353, test=-0.592) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.402, test=-0.396) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.370, test=-0.543) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.366, test=-0.526) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.352, test=-0.594) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.416, test=-0.383) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.379, test=-0.550) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.380, test=-0.512) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.363, test=-0.581) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.413, test=-0.387) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.379, test=-0.533) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.380, test=-0.507) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.362, test=-0.581) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.415, test=-0.392) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.380, test=-0.536) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.381, test=-0.509) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.361, test=-0.586) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.416, test=-0.378) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.380, test=-0.532) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.379, test=-0.511) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.363, test=-0.585) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.415, test=-0.381) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.378, test=-0.531) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.378, test=-0.514) total time=   0.9s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.362, test=-0.584) total time=   0.7s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.323, test=-0.481) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.286, test=-0.588) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.282, test=-0.617) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.281, test=-0.607) total time=   0.1s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.325, test=-0.463) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.283, test=-0.594) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.275, test=-0.604) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.280, test=-0.607) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.323, test=-0.453) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.282, test=-0.589) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.279, test=-0.607) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.280, test=-0.611) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.324, test=-0.454) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.281, test=-0.593) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.278, test=-0.597) total time=   0.9s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.278, test=-0.619) total time=   0.5s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.320, test=-0.464) total time=   0.5s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.281, test=-0.594) total time=   0.5s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.277, test=-0.617) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.280, test=-0.616) total time=   0.5s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.370, test=-0.447) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.328, test=-0.553) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.327, test=-0.541) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.317, test=-0.587) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.367, test=-0.435) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.328, test=-0.556) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.327, test=-0.546) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.319, test=-0.580) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.368, test=-0.419) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.329, test=-0.559) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.334, test=-0.545) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.318, test=-0.589) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.366, test=-0.433) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.324, test=-0.562) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.324, test=-0.554) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.318, test=-0.582) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.364, test=-0.432) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.325, test=-0.562) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.328, test=-0.545) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.316, test=-0.593) total time=   0.5s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.394, test=-0.409) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.347, test=-0.555) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.349, test=-0.528) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.340, test=-0.588) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.394, test=-0.400) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.351, test=-0.550) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.357, test=-0.525) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.339, test=-0.580) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.392, test=-0.404) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.349, test=-0.556) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.356, test=-0.524) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.341, test=-0.578) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.397, test=-0.402) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.350, test=-0.548) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.355, test=-0.527) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.339, test=-0.585) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.393, test=-0.409) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.349, test=-0.551) total time=   0.5s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.355, test=-0.524) total time=   0.5s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.341, test=-0.580) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.370, test=-0.432) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.334, test=-0.573) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.320, test=-0.594) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.319, test=-0.609) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.365, test=-0.421) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.328, test=-0.564) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.319, test=-0.579) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.315, test=-0.608) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.364, test=-0.420) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.329, test=-0.557) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.321, test=-0.577) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.317, test=-0.606) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.362, test=-0.414) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.331, test=-0.559) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.320, test=-0.565) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.314, test=-0.618) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.364, test=-0.414) total time=   0.5s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.330, test=-0.560) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.320, test=-0.563) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.315, test=-0.606) total time=   0.6s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.384, test=-0.418) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.355, test=-0.569) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.353, test=-0.529) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.338, test=-0.592) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.386, test=-0.410) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.354, test=-0.543) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.352, test=-0.539) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.339, test=-0.587) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.388, test=-0.396) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.355, test=-0.544) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.348, test=-0.549) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.335, test=-0.584) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.386, test=-0.405) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.352, test=-0.544) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.346, test=-0.539) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.337, test=-0.590) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.386, test=-0.400) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.353, test=-0.542) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.347, test=-0.538) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.335, test=-0.596) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.408, test=-0.396) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.373, test=-0.530) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.367, test=-0.533) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.354, test=-0.591) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.407, test=-0.393) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.373, test=-0.533) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.371, test=-0.527) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.355, test=-0.572) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.407, test=-0.391) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.372, test=-0.537) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.371, test=-0.525) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.353, test=-0.575) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.407, test=-0.387) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.371, test=-0.527) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.370, test=-0.522) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.354, test=-0.582) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.406, test=-0.387) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.370, test=-0.533) total time=   0.5s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.514) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.353, test=-0.582) total time=   0.5s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.408, test=-0.385) total time=   0.1s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.371, test=-0.541) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.368, test=-0.526) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.355, test=-0.595) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.405, test=-0.384) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.369, test=-0.545) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.368, test=-0.532) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.352, test=-0.584) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.404, test=-0.394) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.370, test=-0.541) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.362, test=-0.523) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.351, test=-0.587) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.402, test=-0.399) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.370, test=-0.540) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.365, test=-0.523) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.350, test=-0.586) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.404, test=-0.388) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.543) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.366, test=-0.521) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.351, test=-0.587) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.405, test=-0.385) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.372, test=-0.541) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.367, test=-0.526) total time=   0.1s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.352, test=-0.587) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.402, test=-0.394) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.371, test=-0.544) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.362, test=-0.530) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.352, test=-0.593) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.403, test=-0.386) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.366, test=-0.542) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.366, test=-0.524) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.353, test=-0.592) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.405, test=-0.393) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.367, test=-0.546) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.364, test=-0.531) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.352, test=-0.587) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.404, test=-0.390) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.539) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.365, test=-0.526) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.350, test=-0.593) total time=   0.5s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.414, test=-0.379) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.381, test=-0.533) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.382, test=-0.512) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.363, test=-0.583) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.417, test=-0.386) total time=   0.2s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.378, test=-0.542) total time=   0.2s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.377, test=-0.512) total time=   0.2s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.359, test=-0.591) total time=   0.2s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.413, test=-0.387) total time=   0.3s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.379, test=-0.526) total time=   0.3s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.381, test=-0.521) total time=   0.3s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.363, test=-0.585) total time=   0.3s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.412, test=-0.386) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.377, test=-0.537) total time=   0.4s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.379, test=-0.515) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.362, test=-0.586) total time=   0.4s\n",
      "[CV 1/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.415, test=-0.385) total time=   0.4s\n",
      "[CV 2/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.377, test=-0.530) total time=   0.5s\n",
      "[CV 3/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.377, test=-0.511) total time=   0.4s\n",
      "[CV 4/4] END criterion=squared_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.361, test=-0.581) total time=   0.4s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.406, test=-0.440) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.367, test=-0.575) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.350, test=-0.544) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.330, test=-0.637) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.401, test=-0.450) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.355, test=-0.565) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.341, test=-0.567) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.339, test=-0.637) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.400, test=-0.455) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.353, test=-0.572) total time=   1.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.346, test=-0.560) total time=   1.3s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.333, test=-0.635) total time=   1.0s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.397, test=-0.450) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.350, test=-0.566) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.344, test=-0.544) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.331, test=-0.640) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.401, test=-0.447) total time=   2.2s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.344, test=-0.575) total time=   2.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.347, test=-0.544) total time=   2.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.330, test=-0.647) total time=   2.2s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.445, test=-0.431) total time=   0.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.404, test=-0.564) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.394, test=-0.528) total time=   0.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.380, test=-0.660) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.445, test=-0.436) total time=   1.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.399, test=-0.547) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.401, test=-0.518) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.376, test=-0.639) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.434, test=-0.438) total time=   1.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.396, test=-0.564) total time=   1.2s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.393, test=-0.529) total time=   1.4s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.380, test=-0.642) total time=   1.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.437, test=-0.437) total time=   1.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.396, test=-0.559) total time=   2.2s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.389, test=-0.520) total time=   1.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.375, test=-0.639) total time=   2.0s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.437, test=-0.437) total time=   2.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.398, test=-0.559) total time=   1.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.393, test=-0.515) total time=   1.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.376, test=-0.641) total time=   1.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.474, test=-0.443) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.426, test=-0.550) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.414, test=-0.523) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.402, test=-0.638) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.477, test=-0.435) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.420, test=-0.548) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.424, test=-0.510) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.401, test=-0.659) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.475, test=-0.430) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.426, test=-0.563) total time=   1.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.431, test=-0.509) total time=   1.2s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.398, test=-0.635) total time=   1.0s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.477, test=-0.432) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.426, test=-0.548) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.423, test=-0.507) total time=   1.4s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.403, test=-0.648) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.476, test=-0.433) total time=   1.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.420, test=-0.553) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.422, test=-0.511) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.404, test=-0.657) total time=   1.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.431, test=-0.434) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.390, test=-0.537) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.396, test=-0.503) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.376, test=-0.645) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.434, test=-0.429) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.387, test=-0.550) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.387, test=-0.535) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.364, test=-0.640) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.426, test=-0.428) total time=   1.2s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.391, test=-0.549) total time=   1.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.384, test=-0.531) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.372, test=-0.646) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.442, test=-0.432) total time=   1.4s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.390, test=-0.538) total time=   1.4s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.383, test=-0.525) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.376, test=-0.651) total time=   1.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.435, test=-0.424) total time=   1.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.392, test=-0.544) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.387, test=-0.532) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.368, test=-0.641) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.459, test=-0.418) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.423, test=-0.542) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.422, test=-0.526) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.401, test=-0.639) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.467, test=-0.429) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.421, test=-0.542) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.418, test=-0.532) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.398, test=-0.649) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.462, test=-0.431) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.411, test=-0.546) total time=   1.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.415, test=-0.513) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.397, test=-0.657) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.466, test=-0.431) total time=   1.4s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.420, test=-0.545) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.412, test=-0.526) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.393, test=-0.648) total time=   1.4s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.463, test=-0.424) total time=   2.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.417, test=-0.538) total time=   1.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.416, test=-0.515) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.396, test=-0.657) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.490, test=-0.430) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.452, test=-0.538) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.434, test=-0.504) total time=   0.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.418, test=-0.670) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.485, test=-0.423) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.445, test=-0.554) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.438, test=-0.518) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.417, test=-0.640) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.494, test=-0.427) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.443, test=-0.530) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.450, test=-0.507) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.416, test=-0.665) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.488, test=-0.428) total time=   1.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.442, test=-0.543) total time=   1.4s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.443, test=-0.509) total time=   1.4s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.416, test=-0.652) total time=   1.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.483, test=-0.426) total time=   1.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.443, test=-0.538) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.438, test=-0.510) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.422, test=-0.658) total time=   1.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.485, test=-0.421) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.438, test=-0.538) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.447, test=-0.517) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.417, test=-0.658) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.486, test=-0.425) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.434, test=-0.535) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.446, test=-0.508) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.410, test=-0.653) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.486, test=-0.430) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.445, test=-0.540) total time=   1.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.437, test=-0.520) total time=   1.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.417, test=-0.662) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.490, test=-0.436) total time=   1.3s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.433, test=-0.543) total time=   1.3s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.450, test=-0.511) total time=   1.3s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.422, test=-0.667) total time=   1.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.488, test=-0.425) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.444, test=-0.541) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.444, test=-0.512) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.415, test=-0.660) total time=   1.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.490, test=-0.442) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.440, test=-0.536) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.449, test=-0.514) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.422, test=-0.678) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.484, test=-0.429) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.437, test=-0.533) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.445, test=-0.514) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.412, test=-0.647) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.483, test=-0.427) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.434, test=-0.539) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.450, test=-0.508) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.415, test=-0.665) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.489, test=-0.426) total time=   1.3s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.437, test=-0.539) total time=   1.3s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.444, test=-0.510) total time=   1.3s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.413, test=-0.656) total time=   1.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.492, test=-0.432) total time=   1.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.438, test=-0.542) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.444, test=-0.509) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.415, test=-0.655) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.508, test=-0.429) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.454, test=-0.538) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.449, test=-0.518) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.433, test=-0.682) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.506, test=-0.422) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.446, test=-0.538) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.464, test=-0.522) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.428, test=-0.664) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.504, test=-0.435) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.449, test=-0.540) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.455, test=-0.508) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.431, test=-0.664) total time=   1.0s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.499, test=-0.435) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.451, test=-0.543) total time=   1.3s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.459, test=-0.498) total time=   1.3s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.425, test=-0.665) total time=   1.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.500, test=-0.423) total time=   1.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.451, test=-0.537) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.455, test=-0.506) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.432, test=-0.661) total time=   1.4s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.353, test=-0.484) total time=   0.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.317, test=-0.570) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.314, test=-0.569) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.316, test=-0.616) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.364, test=-0.466) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.318, test=-0.573) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.311, test=-0.560) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.311, test=-0.623) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.357, test=-0.471) total time=   1.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.317, test=-0.560) total time=   1.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.312, test=-0.572) total time=   1.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.313, test=-0.614) total time=   1.1s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.358, test=-0.464) total time=   1.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.313, test=-0.573) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.312, test=-0.560) total time=   1.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.311, test=-0.620) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.351, test=-0.466) total time=   1.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.315, test=-0.572) total time=   1.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.309, test=-0.561) total time=   1.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.310, test=-0.620) total time=   1.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.424, test=-0.439) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.383, test=-0.563) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.375, test=-0.532) total time=   0.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.367, test=-0.646) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.421, test=-0.444) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.378, test=-0.549) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.369, test=-0.537) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.363, test=-0.640) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.419, test=-0.434) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.385, test=-0.546) total time=   1.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.374, test=-0.532) total time=   1.2s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.359, test=-0.637) total time=   1.1s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.419, test=-0.449) total time=   1.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.376, test=-0.549) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.371, test=-0.532) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.364, test=-0.631) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.420, test=-0.442) total time=   1.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.377, test=-0.544) total time=   2.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.375, test=-0.528) total time=   1.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.364, test=-0.624) total time=   1.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.456, test=-0.429) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.431, test=-0.546) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.411, test=-0.519) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.398, test=-0.654) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.471, test=-0.439) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.417, test=-0.543) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.414, test=-0.516) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.402, test=-0.641) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.464, test=-0.431) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.419, test=-0.541) total time=   1.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.408, test=-0.509) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.396, test=-0.637) total time=   1.2s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.463, test=-0.430) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.415, test=-0.539) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.417, test=-0.509) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.395, test=-0.639) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.460, test=-0.427) total time=   2.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.417, test=-0.534) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.410, test=-0.504) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.395, test=-0.639) total time=   1.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.416, test=-0.433) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.367, test=-0.549) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.359, test=-0.564) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.359, test=-0.637) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.424, test=-0.433) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.376, test=-0.551) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.378, test=-0.524) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.367, test=-0.631) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.411, test=-0.430) total time=   1.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.366, test=-0.533) total time=   1.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.366, test=-0.543) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.366, test=-0.628) total time=   1.2s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.412, test=-0.429) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.369, test=-0.552) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.375, test=-0.527) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.361, test=-0.647) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.419, test=-0.427) total time=   1.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.367, test=-0.542) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.370, test=-0.536) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.363, test=-0.634) total time=   1.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.447, test=-0.444) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.404, test=-0.525) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.421, test=-0.505) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.390, test=-0.643) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.453, test=-0.438) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.415, test=-0.538) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.403, test=-0.529) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.387, test=-0.642) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.452, test=-0.422) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.411, test=-0.539) total time=   1.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.409, test=-0.516) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.389, test=-0.644) total time=   1.0s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.451, test=-0.421) total time=   1.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.405, test=-0.540) total time=   1.4s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.404, test=-0.517) total time=   1.4s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.393, test=-0.650) total time=   1.4s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.450, test=-0.432) total time=   1.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.406, test=-0.527) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.404, test=-0.526) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.388, test=-0.646) total time=   1.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.483, test=-0.425) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.432, test=-0.539) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.432, test=-0.507) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.414, test=-0.640) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.481, test=-0.421) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.431, test=-0.548) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.428, test=-0.516) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.416, test=-0.661) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.475, test=-0.425) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.431, test=-0.535) total time=   1.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.438, test=-0.513) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.410, test=-0.654) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.482, test=-0.423) total time=   1.4s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.432, test=-0.531) total time=   1.4s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.429, test=-0.518) total time=   1.4s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.413, test=-0.651) total time=   1.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.481, test=-0.427) total time=   1.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.428, test=-0.531) total time=   1.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.439, test=-0.511) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.411, test=-0.651) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.481, test=-0.421) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.430, test=-0.536) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.448, test=-0.494) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.412, test=-0.660) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.486, test=-0.430) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.426, test=-0.543) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.449, test=-0.506) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.413, test=-0.648) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.480, test=-0.420) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.434, test=-0.536) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.433, test=-0.510) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.416, test=-0.664) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.484, test=-0.424) total time=   1.3s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.433, test=-0.535) total time=   1.4s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.439, test=-0.519) total time=   1.4s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.412, test=-0.653) total time=   1.4s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.485, test=-0.424) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.430, test=-0.535) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.440, test=-0.521) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.417, test=-0.658) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.480, test=-0.425) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.437, test=-0.537) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.448, test=-0.528) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.416, test=-0.656) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.477, test=-0.425) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.445, test=-0.541) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.446, test=-0.512) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.417, test=-0.663) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.481, test=-0.428) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.436, test=-0.536) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.431, test=-0.524) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.419, test=-0.662) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.477, test=-0.426) total time=   1.3s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.434, test=-0.538) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.439, test=-0.504) total time=   1.4s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.411, test=-0.650) total time=   1.4s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.486, test=-0.426) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.434, test=-0.537) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.441, test=-0.511) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.420, test=-0.671) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.500, test=-0.428) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.450, test=-0.535) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.472, test=-0.515) total time=   0.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.424, test=-0.659) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.494, test=-0.430) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.443, test=-0.536) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.462, test=-0.502) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.431, test=-0.674) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.497, test=-0.425) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.448, test=-0.536) total time=   1.2s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.458, test=-0.505) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.427, test=-0.654) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.499, test=-0.425) total time=   1.3s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.450, test=-0.539) total time=   1.4s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.451, test=-0.504) total time=   1.3s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.423, test=-0.661) total time=   1.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.500, test=-0.431) total time=   1.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.449, test=-0.537) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.457, test=-0.515) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.427, test=-0.661) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.364, test=-0.467) total time=   0.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.315, test=-0.582) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.310, test=-0.565) total time=   0.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.315, test=-0.638) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.361, test=-0.466) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.317, test=-0.565) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.308, test=-0.568) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.315, test=-0.629) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.353, test=-0.468) total time=   1.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.314, test=-0.574) total time=   1.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.310, test=-0.591) total time=   1.4s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.306, test=-0.619) total time=   1.1s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.352, test=-0.460) total time=   1.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.311, test=-0.567) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.311, test=-0.575) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.306, test=-0.618) total time=   1.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.358, test=-0.464) total time=   1.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.317, test=-0.568) total time=   2.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.310, test=-0.565) total time=   2.4s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.307, test=-0.627) total time=   1.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.424, test=-0.434) total time=   0.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.375, test=-0.555) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.381, test=-0.523) total time=   0.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.364, test=-0.632) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.424, test=-0.438) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.384, test=-0.543) total time=   1.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.377, test=-0.523) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.366, test=-0.649) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.420, test=-0.441) total time=   1.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.374, test=-0.555) total time=   1.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.375, test=-0.525) total time=   1.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.367, test=-0.632) total time=   1.1s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.418, test=-0.434) total time=   1.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.375, test=-0.550) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.374, test=-0.527) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.363, test=-0.616) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.420, test=-0.438) total time=   1.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.372, test=-0.554) total time=   2.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.373, test=-0.524) total time=   2.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.362, test=-0.635) total time=   1.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.463, test=-0.437) total time=   0.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.412, test=-0.551) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.407, test=-0.505) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.393, test=-0.636) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.457, test=-0.425) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.411, test=-0.529) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.415, test=-0.505) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.391, test=-0.634) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.471, test=-0.430) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.416, test=-0.542) total time=   1.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.422, test=-0.500) total time=   1.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.393, test=-0.645) total time=   1.0s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.462, test=-0.425) total time=   1.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.420, test=-0.537) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.412, test=-0.514) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.395, test=-0.645) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.464, test=-0.430) total time=   1.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.412, test=-0.540) total time=   2.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.412, test=-0.509) total time=   2.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.398, test=-0.640) total time=   1.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.411, test=-0.426) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.380, test=-0.536) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.365, test=-0.548) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.368, test=-0.646) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.411, test=-0.439) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.382, test=-0.541) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.371, test=-0.542) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.363, test=-0.626) total time=   1.1s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.419, test=-0.438) total time=   1.2s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.376, test=-0.544) total time=   1.2s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.371, test=-0.525) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.363, test=-0.634) total time=   1.2s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.415, test=-0.434) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.373, test=-0.537) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.374, test=-0.520) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.363, test=-0.639) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.413, test=-0.428) total time=   2.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.374, test=-0.540) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.368, test=-0.535) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.364, test=-0.636) total time=   1.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.464, test=-0.429) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.412, test=-0.542) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.412, test=-0.514) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.398, test=-0.650) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.452, test=-0.434) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.408, test=-0.535) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.408, test=-0.510) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.394, test=-0.662) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.448, test=-0.422) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.403, test=-0.540) total time=   1.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.407, test=-0.511) total time=   1.2s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.388, test=-0.634) total time=   1.0s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.456, test=-0.428) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.409, test=-0.534) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.403, test=-0.522) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.393, test=-0.640) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.452, test=-0.432) total time=   1.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.405, test=-0.536) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.408, test=-0.515) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.393, test=-0.642) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.479, test=-0.430) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.437, test=-0.545) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.442, test=-0.499) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.408, test=-0.648) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.471, test=-0.429) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.433, test=-0.528) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.450, test=-0.507) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.412, test=-0.645) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.479, test=-0.430) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.442, test=-0.534) total time=   1.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.430, test=-0.506) total time=   1.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.420, test=-0.657) total time=   1.2s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.478, test=-0.421) total time=   1.4s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.430, test=-0.540) total time=   1.4s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.437, test=-0.513) total time=   1.4s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.412, test=-0.649) total time=   1.4s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.477, test=-0.426) total time=   1.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.432, test=-0.536) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.437, test=-0.504) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.415, test=-0.650) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.478, test=-0.425) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.440, test=-0.543) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.453, test=-0.525) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.421, test=-0.659) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.485, test=-0.434) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.437, test=-0.540) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.435, test=-0.517) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.420, test=-0.655) total time=   1.0s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.485, test=-0.426) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.434, test=-0.550) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.441, test=-0.515) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.415, test=-0.658) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.482, test=-0.421) total time=   1.3s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.429, test=-0.539) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.438, test=-0.515) total time=   1.3s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.421, test=-0.668) total time=   1.4s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.478, test=-0.427) total time=   1.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.431, test=-0.540) total time=   2.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.443, test=-0.517) total time=   1.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.419, test=-0.671) total time=   1.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.477, test=-0.417) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.428, test=-0.544) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.455, test=-0.516) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.413, test=-0.650) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.481, test=-0.421) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.434, test=-0.535) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.439, test=-0.510) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.418, test=-0.652) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.480, test=-0.420) total time=   1.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.436, test=-0.541) total time=   1.2s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.438, test=-0.514) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.418, test=-0.649) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.483, test=-0.434) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.431, test=-0.533) total time=   1.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.445, test=-0.509) total time=   1.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.416, test=-0.656) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.480, test=-0.430) total time=   1.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.432, test=-0.535) total time=   2.0s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.443, test=-0.515) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.415, test=-0.656) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.496, test=-0.436) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.440, test=-0.541) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.443, test=-0.509) total time=   0.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.425, test=-0.654) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.502, test=-0.422) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.446, test=-0.536) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.450, test=-0.523) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.427, test=-0.666) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.491, test=-0.426) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.455, test=-0.539) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.457, test=-0.513) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.425, test=-0.654) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.499, test=-0.430) total time=   1.3s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.446, test=-0.534) total time=   1.3s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.460, test=-0.512) total time=   1.3s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.424, test=-0.655) total time=   1.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.497, test=-0.431) total time=   1.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.449, test=-0.538) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.454, test=-0.514) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.424, test=-0.654) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.360, test=-0.471) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.307, test=-0.569) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.314, test=-0.625) total time=   0.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.311, test=-0.633) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.358, test=-0.464) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.314, test=-0.584) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.307, test=-0.565) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.312, test=-0.622) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.350, test=-0.467) total time=   1.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.314, test=-0.575) total time=   1.2s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.314, test=-0.563) total time=   1.3s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.314, test=-0.622) total time=   1.1s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.353, test=-0.461) total time=   1.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.314, test=-0.568) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.314, test=-0.550) total time=   1.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.308, test=-0.612) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.351, test=-0.462) total time=   1.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.317, test=-0.566) total time=   1.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.319, test=-0.558) total time=   1.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.307, test=-0.623) total time=   2.0s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.424, test=-0.450) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.373, test=-0.565) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.384, test=-0.520) total time=   0.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.364, test=-0.634) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.423, test=-0.435) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.373, test=-0.551) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.376, test=-0.523) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.366, test=-0.640) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.423, test=-0.433) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.375, test=-0.549) total time=   1.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.385, test=-0.514) total time=   1.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.362, test=-0.625) total time=   1.0s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.422, test=-0.430) total time=   1.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.373, test=-0.549) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.377, test=-0.521) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.366, test=-0.631) total time=   1.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.417, test=-0.436) total time=   1.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.381, test=-0.548) total time=   2.3s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.372, test=-0.531) total time=   2.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.365, test=-0.642) total time=   2.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.460, test=-0.437) total time=   0.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.411, test=-0.554) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.417, test=-0.525) total time=   0.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.393, test=-0.650) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.452, test=-0.423) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.416, test=-0.534) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.410, test=-0.514) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.398, test=-0.654) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.468, test=-0.436) total time=   1.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.410, test=-0.541) total time=   1.4s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.414, test=-0.515) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.396, test=-0.639) total time=   1.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.462, test=-0.426) total time=   1.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.409, test=-0.539) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.417, test=-0.512) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.398, test=-0.648) total time=   1.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.462, test=-0.429) total time=   2.2s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.416, test=-0.541) total time=   2.2s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.418, test=-0.506) total time=   2.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.397, test=-0.646) total time=   1.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.424, test=-0.439) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.380, test=-0.547) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.382, test=-0.523) total time=   0.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.365, test=-0.631) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.409, test=-0.425) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.374, test=-0.550) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.376, test=-0.540) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.358, test=-0.635) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.420, test=-0.437) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.373, test=-0.536) total time=   1.2s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.372, test=-0.539) total time=   1.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.363, test=-0.629) total time=   1.0s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.416, test=-0.431) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.369, test=-0.539) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.369, test=-0.541) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.360, test=-0.642) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.414, test=-0.435) total time=   1.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.368, test=-0.539) total time=   1.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.531) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.363, test=-0.630) total time=   1.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.441, test=-0.440) total time=   0.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.402, test=-0.546) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.405, test=-0.518) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.391, test=-0.643) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.457, test=-0.432) total time=   1.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.409, test=-0.538) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.407, test=-0.524) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.390, test=-0.630) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.444, test=-0.422) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.401, test=-0.545) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.409, test=-0.513) total time=   1.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.392, test=-0.645) total time=   1.1s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.449, test=-0.427) total time=   1.4s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.408, test=-0.536) total time=   1.4s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.409, test=-0.509) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.394, test=-0.652) total time=   1.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.450, test=-0.428) total time=   1.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.408, test=-0.535) total time=   1.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.402, test=-0.521) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.389, test=-0.655) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.487, test=-0.429) total time=   0.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.432, test=-0.537) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.448, test=-0.512) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.414, test=-0.644) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.475, test=-0.430) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.432, test=-0.529) total time=   0.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.431, test=-0.518) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.413, test=-0.655) total time=   0.6s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.476, test=-0.424) total time=   0.8s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.432, test=-0.528) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.446, test=-0.504) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.409, test=-0.645) total time=   0.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.481, test=-0.428) total time=   1.4s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.434, test=-0.535) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.438, test=-0.503) total time=   1.3s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.416, test=-0.644) total time=   1.2s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.484, test=-0.428) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.435, test=-0.537) total time=   1.4s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.433, test=-0.516) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.414, test=-0.645) total time=   1.4s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.479, test=-0.424) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.443, test=-0.542) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.433, test=-0.503) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.424, test=-0.663) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.484, test=-0.426) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.432, test=-0.545) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.438, test=-0.513) total time=   0.8s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.422, test=-0.671) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.486, test=-0.428) total time=   1.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.431, test=-0.537) total time=   1.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.445, test=-0.514) total time=   1.1s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.415, test=-0.658) total time=   1.4s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.489, test=-0.430) total time=   1.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.434, test=-0.536) total time=   1.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.446, test=-0.505) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.412, test=-0.653) total time=   1.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.481, test=-0.427) total time=   1.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.436, test=-0.535) total time=   1.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.444, test=-0.511) total time=   1.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.411, test=-0.662) total time=   1.9s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.479, test=-0.416) total time=   0.6s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.436, test=-0.536) total time=   0.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.444, test=-0.520) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.416, test=-0.648) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.481, test=-0.436) total time=   1.1s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.434, test=-0.544) total time=   1.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.436, test=-0.518) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.415, test=-0.653) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.487, test=-0.421) total time=   1.0s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.436, test=-0.532) total time=   1.1s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.440, test=-0.518) total time=   1.0s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.421, test=-0.660) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.484, test=-0.429) total time=   1.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.434, test=-0.539) total time=   1.6s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.442, test=-0.517) total time=   1.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.414, test=-0.648) total time=   1.4s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.486, test=-0.425) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.439, test=-0.541) total time=   1.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.434, test=-0.519) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.414, test=-0.658) total time=   1.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.502, test=-0.429) total time=   0.4s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.451, test=-0.542) total time=   0.5s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.458, test=-0.521) total time=   0.5s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.435, test=-0.675) total time=   0.5s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.496, test=-0.428) total time=   0.7s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.445, test=-0.537) total time=   0.7s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.458, test=-0.509) total time=   0.7s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.430, test=-0.663) total time=   0.7s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.497, test=-0.428) total time=   0.9s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.454, test=-0.530) total time=   0.9s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.460, test=-0.515) total time=   0.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.429, test=-0.662) total time=   0.8s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.495, test=-0.423) total time=   1.3s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.446, test=-0.531) total time=   1.4s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.456, test=-0.506) total time=   1.6s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.425, test=-0.651) total time=   1.3s\n",
      "[CV 1/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.499, test=-0.431) total time=   1.5s\n",
      "[CV 2/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.444, test=-0.534) total time=   1.8s\n",
      "[CV 3/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.454, test=-0.513) total time=   1.9s\n",
      "[CV 4/4] END criterion=absolute_error, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.429, test=-0.657) total time=   1.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.336, test=-0.458) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.305, test=-0.577) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.299, test=-0.587) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.291, test=-0.613) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.337, test=-0.461) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.303, test=-0.595) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.291, test=-0.577) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.295, test=-0.611) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.335, test=-0.452) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.307, test=-0.579) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.294, test=-0.598) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.290, test=-0.598) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.337, test=-0.443) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.302, test=-0.580) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.293, test=-0.589) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.289, test=-0.603) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.334, test=-0.451) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.305, test=-0.577) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.293, test=-0.579) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.292, test=-0.607) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.382, test=-0.422) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.342, test=-0.560) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.336, test=-0.537) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.327, test=-0.596) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.376, test=-0.415) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.342, test=-0.559) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.337, test=-0.537) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.333, test=-0.591) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.381, test=-0.411) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.342, test=-0.561) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.340, test=-0.551) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.326, test=-0.596) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.378, test=-0.416) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.341, test=-0.563) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.337, test=-0.536) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.328, test=-0.590) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.373, test=-0.419) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.339, test=-0.561) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.340, test=-0.533) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.328, test=-0.594) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.404, test=-0.404) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.366, test=-0.552) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.365, test=-0.503) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.354, test=-0.591) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.402, test=-0.395) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.362, test=-0.551) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.364, test=-0.505) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.355, test=-0.597) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.398, test=-0.405) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.366, test=-0.553) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.365, test=-0.507) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.349, test=-0.590) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.402, test=-0.397) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.366, test=-0.555) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.361, test=-0.515) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.352, test=-0.584) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.406, test=-0.398) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.363, test=-0.555) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.364, test=-0.513) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.350, test=-0.587) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.368, test=-0.403) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.341, test=-0.567) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.328, test=-0.577) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.330, test=-0.607) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.367, test=-0.419) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.342, test=-0.570) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.331, test=-0.564) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.324, test=-0.594) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.375, test=-0.402) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.338, test=-0.556) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.332, test=-0.544) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.324, test=-0.606) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.372, test=-0.408) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.337, test=-0.562) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.329, test=-0.564) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.324, test=-0.605) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.366, test=-0.418) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.340, test=-0.562) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.326, test=-0.561) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.324, test=-0.610) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.391, test=-0.412) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.367, test=-0.549) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.355, test=-0.542) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.347, test=-0.594) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.391, test=-0.402) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.366, test=-0.555) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.354, test=-0.532) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.348, test=-0.586) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.396, test=-0.396) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.367, test=-0.556) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.357, test=-0.526) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.350, test=-0.594) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.392, test=-0.405) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.366, test=-0.560) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.357, test=-0.525) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.347, test=-0.586) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.392, test=-0.398) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.364, test=-0.549) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.353, test=-0.531) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.348, test=-0.597) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.413, test=-0.381) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.381, test=-0.542) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.378, test=-0.523) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.366, test=-0.592) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.412, test=-0.380) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.381, test=-0.555) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.377, test=-0.506) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.365, test=-0.586) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.413, test=-0.394) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.379, test=-0.553) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.376, test=-0.515) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.363, test=-0.589) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.415, test=-0.385) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.380, test=-0.546) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.375, test=-0.511) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.363, test=-0.587) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.413, test=-0.389) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.380, test=-0.548) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.375, test=-0.515) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.365, test=-0.587) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.410, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.379, test=-0.558) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.371, test=-0.507) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.363, test=-0.587) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.407, test=-0.392) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.377, test=-0.554) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.371, test=-0.544) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.362, test=-0.589) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.406, test=-0.393) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.379, test=-0.550) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.372, test=-0.521) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.362, test=-0.588) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.410, test=-0.384) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.379, test=-0.554) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.371, test=-0.519) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.362, test=-0.592) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.407, test=-0.385) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.377, test=-0.553) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.370, test=-0.519) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.363, test=-0.591) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.409, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.379, test=-0.548) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.369, test=-0.520) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.366, test=-0.603) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.410, test=-0.391) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.374, test=-0.552) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.375, test=-0.511) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.362, test=-0.602) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.410, test=-0.377) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.377, test=-0.550) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.373, test=-0.514) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.361, test=-0.594) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.412, test=-0.384) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.379, test=-0.547) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.369, test=-0.519) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.361, test=-0.594) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.412, test=-0.388) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.376, test=-0.556) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.371, test=-0.517) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.362, test=-0.595) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.422, test=-0.378) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.387, test=-0.528) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.385, test=-0.513) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.377, test=-0.591) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.419, test=-0.384) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.388, test=-0.550) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.382, test=-0.517) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.372, test=-0.586) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.423, test=-0.374) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.389, test=-0.549) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.384, test=-0.508) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.372, test=-0.584) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.422, test=-0.386) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.385, test=-0.551) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.381, test=-0.513) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.374, test=-0.585) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.421, test=-0.382) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.388, test=-0.548) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.383, test=-0.505) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=10, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.374, test=-0.588) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.325, test=-0.458) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.296, test=-0.598) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.287, test=-0.599) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.285, test=-0.605) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.328, test=-0.461) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.297, test=-0.588) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.288, test=-0.597) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.287, test=-0.604) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.320, test=-0.469) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.297, test=-0.570) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.286, test=-0.587) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.286, test=-0.617) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.323, test=-0.466) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.296, test=-0.586) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.288, test=-0.596) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.282, test=-0.613) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.323, test=-0.462) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.296, test=-0.585) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.284, test=-0.592) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.283, test=-0.606) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.376, test=-0.415) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.337, test=-0.563) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.332, test=-0.556) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.326, test=-0.593) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.372, test=-0.426) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.338, test=-0.561) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.329, test=-0.539) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.325, test=-0.602) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.371, test=-0.408) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.338, test=-0.554) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.330, test=-0.530) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.326, test=-0.587) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.371, test=-0.410) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.339, test=-0.564) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.334, test=-0.539) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.325, test=-0.589) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.370, test=-0.424) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.338, test=-0.566) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.333, test=-0.548) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.326, test=-0.594) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.401, test=-0.407) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.368, test=-0.552) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.361, test=-0.505) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.354, test=-0.593) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.402, test=-0.397) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.361, test=-0.549) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.357, test=-0.529) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.350, test=-0.593) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.401, test=-0.398) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.363, test=-0.552) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.363, test=-0.518) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.351, test=-0.589) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.398, test=-0.400) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.362, test=-0.557) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.359, test=-0.509) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.350, test=-0.590) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.399, test=-0.402) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.363, test=-0.554) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.361, test=-0.518) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.349, test=-0.587) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.364, test=-0.417) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.340, test=-0.563) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.326, test=-0.559) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.326, test=-0.596) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.367, test=-0.417) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.337, test=-0.559) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.319, test=-0.579) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.320, test=-0.596) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.362, test=-0.422) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.336, test=-0.553) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.323, test=-0.566) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.322, test=-0.611) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.361, test=-0.423) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.337, test=-0.563) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.324, test=-0.561) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.321, test=-0.603) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.364, test=-0.418) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.338, test=-0.560) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.322, test=-0.566) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.320, test=-0.603) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.390, test=-0.395) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.360, test=-0.549) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.353, test=-0.532) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.346, test=-0.601) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.388, test=-0.407) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.361, test=-0.548) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.356, test=-0.534) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.351, test=-0.597) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.390, test=-0.403) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.362, test=-0.551) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.350, test=-0.538) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.345, test=-0.596) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.393, test=-0.405) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.362, test=-0.552) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.351, test=-0.532) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.346, test=-0.592) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.390, test=-0.399) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.363, test=-0.549) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.351, test=-0.540) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.344, test=-0.597) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.408, test=-0.400) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.381, test=-0.548) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.376, test=-0.501) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.363, test=-0.595) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.414, test=-0.385) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.379, test=-0.546) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.374, test=-0.515) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.364, test=-0.588) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.408, test=-0.393) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.380, test=-0.556) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.374, test=-0.509) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.365, test=-0.589) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.412, test=-0.390) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.381, test=-0.551) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.372, test=-0.517) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.365, test=-0.591) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.411, test=-0.387) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.377, test=-0.553) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.373, test=-0.508) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.365, test=-0.591) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.411, test=-0.391) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.378, test=-0.565) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.369, test=-0.529) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.364, test=-0.604) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.410, test=-0.392) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.377, test=-0.547) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.370, test=-0.518) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.360, test=-0.592) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.407, test=-0.389) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.377, test=-0.563) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.374, test=-0.518) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.363, test=-0.597) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.408, test=-0.388) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.377, test=-0.553) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.369, test=-0.523) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.361, test=-0.600) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.408, test=-0.385) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.376, test=-0.554) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.371, test=-0.520) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.362, test=-0.592) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.414, test=-0.392) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.377, test=-0.551) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.367, test=-0.515) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.364, test=-0.589) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.413, test=-0.382) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.376, test=-0.550) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.372, test=-0.509) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.361, test=-0.589) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.407, test=-0.391) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.379, test=-0.550) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.371, test=-0.521) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.361, test=-0.593) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.408, test=-0.386) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.377, test=-0.550) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.372, test=-0.515) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.360, test=-0.591) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.408, test=-0.392) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.376, test=-0.554) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.371, test=-0.519) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.362, test=-0.596) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.420, test=-0.392) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.387, test=-0.547) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.384, test=-0.520) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.375, test=-0.594) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.424, test=-0.378) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.387, test=-0.549) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.383, test=-0.507) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.373, test=-0.592) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.423, test=-0.377) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.387, test=-0.553) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.385, test=-0.506) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.373, test=-0.596) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.423, test=-0.375) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.388, test=-0.549) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.383, test=-0.508) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.372, test=-0.588) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.423, test=-0.379) total time=   0.6s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.388, test=-0.550) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.383, test=-0.505) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=15, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.372, test=-0.586) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.325, test=-0.486) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.292, test=-0.599) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.284, test=-0.596) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.284, test=-0.619) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.326, test=-0.461) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.294, test=-0.579) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.286, test=-0.586) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.281, test=-0.612) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.320, test=-0.464) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.298, test=-0.588) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.288, test=-0.577) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.285, test=-0.615) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.324, test=-0.471) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.292, test=-0.578) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.283, test=-0.595) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.288, test=-0.608) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.323, test=-0.467) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.297, test=-0.579) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.285, test=-0.602) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.284, test=-0.616) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.373, test=-0.415) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.337, test=-0.565) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.334, test=-0.553) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.328, test=-0.599) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.370, test=-0.418) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.340, test=-0.574) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.332, test=-0.543) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.326, test=-0.590) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.370, test=-0.426) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.334, test=-0.558) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.332, test=-0.543) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.328, test=-0.596) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.371, test=-0.418) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.337, test=-0.560) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.335, test=-0.530) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.327, test=-0.598) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.368, test=-0.427) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.340, test=-0.555) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.333, test=-0.536) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.326, test=-0.596) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.400, test=-0.409) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.361, test=-0.559) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.362, test=-0.512) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.355, test=-0.585) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.400, test=-0.403) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.363, test=-0.546) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.366, test=-0.513) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.348, test=-0.583) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.400, test=-0.403) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.363, test=-0.544) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.362, test=-0.526) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.351, test=-0.589) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.401, test=-0.402) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.364, test=-0.553) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.359, test=-0.517) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.349, test=-0.585) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.398, test=-0.401) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.361, test=-0.556) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.361, test=-0.522) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.349, test=-0.590) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.364, test=-0.414) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.336, test=-0.573) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.321, test=-0.567) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.324, test=-0.607) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.365, test=-0.412) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.335, test=-0.561) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.327, test=-0.554) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.322, test=-0.602) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.365, test=-0.417) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.338, test=-0.557) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.322, test=-0.574) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.321, test=-0.613) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.364, test=-0.412) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.336, test=-0.564) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.326, test=-0.556) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.320, test=-0.602) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.365, test=-0.415) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.336, test=-0.571) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.324, test=-0.562) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.323, test=-0.597) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.399, test=-0.397) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.362, test=-0.549) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.359, test=-0.550) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.346, test=-0.600) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.389, test=-0.402) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.362, test=-0.553) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.355, test=-0.531) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.346, test=-0.597) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.392, test=-0.384) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.363, test=-0.549) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.353, test=-0.531) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.347, test=-0.596) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.393, test=-0.402) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.361, test=-0.550) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.352, test=-0.535) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.348, test=-0.586) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.390, test=-0.400) total time=   0.6s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.362, test=-0.556) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.354, test=-0.527) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.346, test=-0.591) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.414, test=-0.380) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.381, test=-0.550) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.376, test=-0.511) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.364, test=-0.597) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.411, test=-0.390) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.378, test=-0.544) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.370, test=-0.519) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.367, test=-0.587) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.410, test=-0.390) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.381, test=-0.549) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.377, test=-0.505) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.365, test=-0.587) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.411, test=-0.389) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.378, test=-0.545) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.373, test=-0.508) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.367, test=-0.584) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.413, test=-0.382) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.381, test=-0.545) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.372, test=-0.513) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.365, test=-0.584) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.412, test=-0.391) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.379, test=-0.556) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.371, test=-0.530) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.364, test=-0.602) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.409, test=-0.386) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.380, test=-0.552) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.367, test=-0.518) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.360, test=-0.589) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.408, test=-0.382) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.378, test=-0.559) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.372, test=-0.519) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.362, test=-0.596) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.410, test=-0.384) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.376, test=-0.547) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.369, test=-0.526) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.361, test=-0.589) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.409, test=-0.386) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.375, test=-0.552) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.522) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.361, test=-0.591) total time=   0.6s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.406, test=-0.389) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.378, test=-0.547) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.368, test=-0.526) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.363, test=-0.593) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.405, test=-0.389) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.376, test=-0.551) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.371, test=-0.515) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.361, test=-0.593) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.407, test=-0.393) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.376, test=-0.560) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.372, test=-0.519) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.360, test=-0.587) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.411, test=-0.384) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.378, test=-0.558) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.368, test=-0.517) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.363, test=-0.597) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.410, test=-0.391) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.377, test=-0.553) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.521) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.362, test=-0.595) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.421, test=-0.384) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.388, test=-0.544) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.386, test=-0.517) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.375, test=-0.591) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.421, test=-0.385) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.391, test=-0.547) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.381, test=-0.511) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.373, test=-0.589) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.422, test=-0.378) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.387, test=-0.542) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.381, test=-0.515) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.373, test=-0.592) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.423, test=-0.378) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.386, test=-0.547) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.379, test=-0.511) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.372, test=-0.593) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.421, test=-0.383) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.388, test=-0.547) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.383, test=-0.510) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=20, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.371, test=-0.585) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.328, test=-0.476) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.300, test=-0.574) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.289, test=-0.584) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.288, test=-0.613) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.321, test=-0.465) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.293, test=-0.593) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.284, test=-0.592) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.286, test=-0.603) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.320, test=-0.473) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.295, test=-0.576) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.286, test=-0.587) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.286, test=-0.612) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.322, test=-0.462) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.297, test=-0.579) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.282, test=-0.604) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.284, test=-0.612) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.320, test=-0.478) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.298, test=-0.587) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.284, test=-0.585) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.286, test=-0.601) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.365, test=-0.429) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.336, test=-0.588) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.335, test=-0.556) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.329, test=-0.597) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.368, test=-0.427) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.339, test=-0.559) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.331, test=-0.554) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.327, test=-0.600) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.371, test=-0.420) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.339, test=-0.560) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.333, test=-0.541) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.325, test=-0.594) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.370, test=-0.425) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.336, test=-0.563) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.333, test=-0.544) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.328, test=-0.595) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.420) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.340, test=-0.562) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.332, test=-0.541) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.325, test=-0.591) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.401, test=-0.397) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.372, test=-0.551) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.361, test=-0.513) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.347, test=-0.595) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.402, test=-0.405) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.363, test=-0.556) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.360, test=-0.516) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.349, test=-0.592) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.397, test=-0.407) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.362, test=-0.553) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.361, test=-0.514) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.349, test=-0.580) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.399, test=-0.399) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.365, test=-0.557) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.361, test=-0.514) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.351, test=-0.595) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.399, test=-0.408) total time=   0.6s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.361, test=-0.554) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.358, test=-0.518) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=1, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.350, test=-0.585) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.368, test=-0.416) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.339, test=-0.563) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.328, test=-0.559) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.320, test=-0.607) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.366, test=-0.419) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.336, test=-0.567) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.323, test=-0.580) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.325, test=-0.600) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.367, test=-0.413) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.333, test=-0.563) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.323, test=-0.573) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.324, test=-0.604) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.363, test=-0.423) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.335, test=-0.557) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.322, test=-0.565) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.322, test=-0.599) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.365, test=-0.420) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.336, test=-0.567) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.325, test=-0.558) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.319, test=-0.605) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.391, test=-0.401) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.365, test=-0.558) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.356, test=-0.533) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.344, test=-0.597) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.389, test=-0.402) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.363, test=-0.550) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.354, test=-0.536) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.348, test=-0.589) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.390, test=-0.399) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.364, test=-0.555) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.352, test=-0.530) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.345, test=-0.598) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.392, test=-0.391) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.363, test=-0.550) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.352, test=-0.532) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.346, test=-0.601) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.390, test=-0.401) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.363, test=-0.554) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.352, test=-0.534) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.345, test=-0.596) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.411, test=-0.391) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.382, test=-0.543) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.373, test=-0.511) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.363, test=-0.581) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.412, test=-0.386) total time=   0.5s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.379, test=-0.543) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.371, test=-0.519) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.364, test=-0.591) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.408, test=-0.388) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.380, test=-0.549) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.374, test=-0.518) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.364, test=-0.590) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.414, test=-0.387) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.382, test=-0.549) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.373, test=-0.515) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.366, test=-0.590) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.410, test=-0.392) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.378, test=-0.545) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.373, test=-0.511) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=3, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.366, test=-0.586) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.413, test=-0.385) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.375, test=-0.555) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.375, test=-0.527) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=50, n_jobs=-1;, score=(train=-0.363, test=-0.596) total time=   0.1s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.409, test=-0.391) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.378, test=-0.549) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.374, test=-0.513) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=75, n_jobs=-1;, score=(train=-0.360, test=-0.602) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.410, test=-0.389) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.379, test=-0.547) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.371, test=-0.520) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=100, n_jobs=-1;, score=(train=-0.360, test=-0.597) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.408, test=-0.385) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.378, test=-0.555) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.371, test=-0.518) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=150, n_jobs=-1;, score=(train=-0.361, test=-0.598) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.407, test=-0.399) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.376, test=-0.553) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.370, test=-0.520) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=6, n_estimators=175, n_jobs=-1;, score=(train=-0.362, test=-0.592) total time=   0.8s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.410, test=-0.392) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.382, test=-0.551) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.370, test=-0.512) total time=   0.1s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50, n_jobs=-1;, score=(train=-0.360, test=-0.588) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.408, test=-0.390) total time=   0.3s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.375, test=-0.553) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.370, test=-0.535) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=75, n_jobs=-1;, score=(train=-0.361, test=-0.590) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.408, test=-0.387) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.378, test=-0.551) total time=   0.8s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.371, test=-0.527) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100, n_jobs=-1;, score=(train=-0.361, test=-0.599) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.409, test=-0.389) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.375, test=-0.548) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.367, test=-0.522) total time=   0.7s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=150, n_jobs=-1;, score=(train=-0.363, test=-0.593) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.409, test=-0.386) total time=   0.6s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.377, test=-0.551) total time=   0.5s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.369, test=-0.523) total time=   0.5s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=175, n_jobs=-1;, score=(train=-0.362, test=-0.597) total time=   0.5s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.418, test=-0.386) total time=   0.1s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.388, test=-0.549) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.384, test=-0.526) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=50, n_jobs=-1;, score=(train=-0.374, test=-0.595) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.419, test=-0.377) total time=   0.2s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.386, test=-0.544) total time=   0.2s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.383, test=-0.508) total time=   0.2s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=75, n_jobs=-1;, score=(train=-0.371, test=-0.591) total time=   0.2s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.425, test=-0.379) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.386, test=-0.549) total time=   0.3s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.385, test=-0.505) total time=   0.3s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=100, n_jobs=-1;, score=(train=-0.374, test=-0.587) total time=   0.3s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.423, test=-0.375) total time=   0.4s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.389, test=-0.545) total time=   0.4s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.382, test=-0.501) total time=   0.4s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=150, n_jobs=-1;, score=(train=-0.374, test=-0.594) total time=   0.4s\n",
      "[CV 1/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.423, test=-0.380) total time=   0.7s\n",
      "[CV 2/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.387, test=-0.546) total time=   0.8s\n",
      "[CV 3/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.382, test=-0.507) total time=   0.8s\n",
      "[CV 4/4] END criterion=friedman_mse, max_depth=None, min_samples_leaf=5, min_samples_split=14, n_estimators=175, n_jobs=-1;, score=(train=-0.372, test=-0.585) total time=   0.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, error_score=&#x27;raise&#x27;, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;absolute_error&#x27;,\n",
       "                                       &#x27;friedman_mse&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 15, 20, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [6, 10, 14],\n",
       "                         &#x27;n_estimators&#x27;: [50, 75, 100, 150, 175],\n",
       "                         &#x27;n_jobs&#x27;: [-1]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "             verbose=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4, error_score=&#x27;raise&#x27;, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;absolute_error&#x27;,\n",
       "                                       &#x27;friedman_mse&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 15, 20, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [6, 10, 14],\n",
       "                         &#x27;n_estimators&#x27;: [50, 75, 100, 150, 175],\n",
       "                         &#x27;n_jobs&#x27;: [-1]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "             verbose=7)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: RandomForestRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=10, min_samples_leaf=5, min_samples_split=14,\n",
       "                      n_jobs=-1)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=10, min_samples_leaf=5, min_samples_split=14,\n",
       "                      n_jobs=-1)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise', estimator=RandomForestRegressor(),\n",
       "             param_grid={'criterion': ['squared_error', 'absolute_error',\n",
       "                                       'friedman_mse'],\n",
       "                         'max_depth': [10, 15, 20, None],\n",
       "                         'min_samples_leaf': [1, 3, 5],\n",
       "                         'min_samples_split': [6, 10, 14],\n",
       "                         'n_estimators': [50, 75, 100, 150, 175],\n",
       "                         'n_jobs': [-1]},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error',\n",
       "             verbose=7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['common flares', 'moderate flares', 'severe flares'], axis=1)\n",
    "y = df[['common flares', 'moderate flares', 'severe flares']]\n",
    "\n",
    "ran = RandomForestRegressor()\n",
    "\n",
    "grid_params1 = {\"n_estimators\": [ 50 ,75, 100, 150, 175], \n",
    "               \"criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\"],\n",
    "               \"max_depth\" : [10,15,20,None],\n",
    "               \"min_samples_split\": [6,10,14],\n",
    "               \"min_samples_leaf\": [1,3,5],\n",
    "               \"n_jobs\": [-1],\n",
    "                }\n",
    "rancv = GridSearchCV(ran, grid_params1, scoring=\"neg_mean_squared_error\", cv=4, refit=True, verbose=7, return_train_score=True, error_score='raise')\n",
    "\n",
    "X_train, X_test,  y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "rancv.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c631c714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5012144813588587\n"
     ]
    }
   ],
   "source": [
    "print(rancv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e813d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4845313681391752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV \n",
    "\n",
    "grid_params2 = {\n",
    "    \"alpha\": [0,0.1, 0.5, 0.7, 1, 1.5, 1.7, 2, 5,6,7,8,9,10,\n",
    "              ]\n",
    "}\n",
    "\n",
    "ridgecvval = RidgeCV(alphas=grid_params2[\"alpha\"], fit_intercept=True, scoring=\"neg_mean_squared_error\", cv=4, alpha_per_target=False)\n",
    "ridgecvval.fit(X_train,y_train)\n",
    "print(ridgecvval.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3863f03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1344 candidates, totalling 5376 fits\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.348, test=-0.772) total time=   0.1s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.820) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.868) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-0.959) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.881) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.344, test=-0.714) total time=   0.1s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.821) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-0.952) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.827) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.864) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.828) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.706) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.842) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.738) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.769) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.818) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.732) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.831) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.863) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.854) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.758) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.752) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.809) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.846) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.703) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.827) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.680) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.755) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.853) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.810) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.686) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.787) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.821) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.778) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.679) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.818) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.816) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.820) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.868) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-0.959) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.881) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.821) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-0.952) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.827) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.864) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.828) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.706) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.842) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.738) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.769) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.818) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.732) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.831) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.863) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.854) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.758) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.752) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.809) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.846) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.430, test=-0.473) total time=   0.1s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.703) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.827) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.680) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.755) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.853) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.810) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.686) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.787) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.821) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.778) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.679) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.818) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.816) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.820) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.868) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-0.959) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.881) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.821) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-0.952) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.827) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.864) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.828) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.706) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.2s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.842) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.738) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.769) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.818) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.732) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.831) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.863) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.854) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.758) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.752) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.809) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.846) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.703) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.827) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.680) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.755) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.853) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.810) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.686) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.426, test=-0.526) total time=   0.1s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.787) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.821) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.778) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.679) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.818) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.816) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.820) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.868) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-0.959) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.881) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.821) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-0.952) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.827) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.864) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.828) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.706) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.842) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.738) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.769) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.818) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.732) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.831) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.863) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.854) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.758) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.752) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.809) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.397, test=-0.547) total time=   0.1s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.385, test=-0.597) total time=   0.1s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.846) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.703) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.827) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.680) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.755) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.853) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.810) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.686) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.787) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.821) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.778) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.679) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.818) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.816) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=auto, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.346, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.280, test=-0.787) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.301, test=-0.891) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.319, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.237, test=-0.798) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.846) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-0.993) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.878) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.346, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.280, test=-0.787) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.301, test=-0.891) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.319, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.345, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.280, test=-0.780) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.302, test=-0.902) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.318, test=-0.722) total time=   0.2s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.237, test=-0.802) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.840) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-1.000) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.876) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.345, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.280, test=-0.780) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.302, test=-0.902) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.318, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.342, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.280, test=-0.780) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.302, test=-0.885) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.318, test=-0.723) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.237, test=-0.808) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.985) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.876) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.342, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.280, test=-0.780) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.302, test=-0.885) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.318, test=-0.723) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.342, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.280, test=-0.778) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.302, test=-0.885) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.318, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.237, test=-0.811) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.835) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.985) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.875) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.342, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.280, test=-0.778) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.302, test=-0.885) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.318, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.409, test=-0.517) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.382, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.365, test=-0.621) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.378, test=-0.593) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.728) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.762) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.872) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.815) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.409, test=-0.517) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.382, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.365, test=-0.621) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.378, test=-0.593) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.513) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.383, test=-0.564) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.365, test=-0.622) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.377, test=-0.593) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.728) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.766) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.870) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.812) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.410, test=-0.513) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.383, test=-0.564) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.365, test=-0.622) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.377, test=-0.593) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.398, test=-0.516) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.377, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.609) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.371, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.731) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.764) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.858) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.812) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.398, test=-0.516) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.377, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.609) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.371, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.399, test=-0.525) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.376, test=-0.560) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.367, test=-0.610) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.370, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.733) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.762) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.857) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.814) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.399, test=-0.525) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.376, test=-0.560) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.367, test=-0.610) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.370, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.419, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.404, test=-0.540) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.403, test=-0.569) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.385, test=-0.574) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.756) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.860) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.419, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.404, test=-0.540) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.403, test=-0.569) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.385, test=-0.574) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.411, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.401, test=-0.536) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.399, test=-0.560) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.380, test=-0.577) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.758) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.857) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.411, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.401, test=-0.536) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.399, test=-0.560) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.380, test=-0.577) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.409, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.406, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.402, test=-0.548) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.377, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.699) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.756) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.847) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.793) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.409, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.406, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.402, test=-0.548) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.377, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.404, test=-0.484) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.403, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.401, test=-0.544) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.377, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.749) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.793) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.404, test=-0.484) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.403, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.401, test=-0.544) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.377, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.413, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.409, test=-0.542) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.388, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.794) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.413, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.409, test=-0.542) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.388, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.449) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.407, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.403, test=-0.539) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.384, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.755) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.845) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.804) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.417, test=-0.449) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.407, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.403, test=-0.539) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.384, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.416, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.408, test=-0.528) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.406, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.383, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.754) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.416, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.408, test=-0.528) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.406, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.383, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.418, test=-0.453) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.408, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.406, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.382, test=-0.571) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.418, test=-0.453) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.408, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.406, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.382, test=-0.571) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.439, test=-0.424) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.413, test=-0.541) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.418, test=-0.527) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.401, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.680) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.749) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.847) total time=   0.2s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.785) total time=   0.1s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.439, test=-0.424) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.413, test=-0.541) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.418, test=-0.527) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.401, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.439, test=-0.428) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.412, test=-0.547) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.413, test=-0.535) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.402, test=-0.549) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.682) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.757) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.776) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.439, test=-0.428) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.412, test=-0.547) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.413, test=-0.535) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.402, test=-0.549) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.435, test=-0.440) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.418, test=-0.540) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.418, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.401, test=-0.571) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.749) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.834) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.794) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.435, test=-0.440) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.418, test=-0.540) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.418, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.401, test=-0.571) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.432, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.416, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.415, test=-0.518) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.398, test=-0.572) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.831) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.790) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.432, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.416, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.415, test=-0.518) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.398, test=-0.572) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.452, test=-0.420) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.426, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.414, test=-0.554) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.403, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.672) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.855) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.787) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.452, test=-0.420) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.426, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.414, test=-0.554) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.403, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.448, test=-0.421) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.424, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.414, test=-0.540) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.401, test=-0.545) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.670) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.845) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.777) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.448, test=-0.421) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.424, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.414, test=-0.540) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.401, test=-0.545) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.443, test=-0.439) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.507) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.428, test=-0.530) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.408, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.683) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.739) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.443, test=-0.439) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.507) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.428, test=-0.530) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.408, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.442, test=-0.446) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.430, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.424, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.414, test=-0.553) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.735) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.783) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.442, test=-0.446) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.430, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.424, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.414, test=-0.553) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.413) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.430, test=-0.508) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.429, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.411, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.672) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.795) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.413) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.430, test=-0.508) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.429, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.411, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.459, test=-0.409) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.430, test=-0.500) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.423, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.408, test=-0.542) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.668) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.739) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.782) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.459, test=-0.409) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.430, test=-0.500) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.423, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.408, test=-0.542) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.459, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.432, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.431, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.417, test=-0.541) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.683) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.826) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.780) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.459, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.432, test=-0.496) total time=   0.1s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.431, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.417, test=-0.541) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.452, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.438, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.430, test=-0.517) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.418, test=-0.537) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.693) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.741) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.823) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.777) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.452, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.438, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.430, test=-0.517) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.418, test=-0.537) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.334, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.285, test=-0.786) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.303, test=-0.913) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.315, test=-0.703) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.232, test=-0.802) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.183, test=-0.842) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-1.009) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.878) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.334, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.285, test=-0.786) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.303, test=-0.913) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.315, test=-0.703) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.334, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.284, test=-0.784) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.304, test=-0.916) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.314, test=-0.703) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.232, test=-0.808) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.183, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-1.009) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.877) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.334, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.284, test=-0.784) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.304, test=-0.916) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.314, test=-0.703) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.330, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.284, test=-0.784) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.304, test=-0.898) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.314, test=-0.704) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.232, test=-0.814) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.183, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.993) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.877) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.330, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.284, test=-0.784) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.304, test=-0.898) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.314, test=-0.704) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.330, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.284, test=-0.782) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.304, test=-0.898) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.314, test=-0.704) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.232, test=-0.816) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.183, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.994) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.876) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.330, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.284, test=-0.782) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.304, test=-0.898) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.314, test=-0.704) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.409, test=-0.517) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.385, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.365, test=-0.621) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.378, test=-0.606) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.728) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.764) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.870) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.823) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.409, test=-0.517) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.385, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.365, test=-0.621) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.378, test=-0.606) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.407, test=-0.522) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.378, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.365, test=-0.620) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.379, test=-0.600) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.729) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.865) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.407, test=-0.522) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.378, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.365, test=-0.620) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.379, test=-0.600) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.397, test=-0.519) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.376, test=-0.567) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.364, test=-0.615) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.375, test=-0.601) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.729) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.768) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.858) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.397, test=-0.519) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.376, test=-0.567) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.364, test=-0.615) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.375, test=-0.601) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.396, test=-0.518) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.375, test=-0.569) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.363, test=-0.609) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.376, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.722) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.767) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.858) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.814) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.396, test=-0.518) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.375, test=-0.569) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.363, test=-0.609) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.376, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.418, test=-0.458) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.403, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.407, test=-0.564) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.380, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.755) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.863) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.798) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.418, test=-0.458) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.403, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.407, test=-0.564) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.380, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.413, test=-0.468) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.397, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.561) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.377, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.794) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.413, test=-0.468) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.397, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.404, test=-0.561) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.377, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.409, test=-0.465) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.401, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.402, test=-0.554) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.378, test=-0.584) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.741) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.409, test=-0.465) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.401, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.402, test=-0.554) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.378, test=-0.584) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.409, test=-0.472) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.398, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.403, test=-0.548) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.376, test=-0.586) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.741) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.409, test=-0.472) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.398, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.403, test=-0.548) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.376, test=-0.586) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.427, test=-0.432) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.403, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.405, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.386, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.749) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.853) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.799) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.427, test=-0.432) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.403, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.405, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.386, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.452) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.528) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.406, test=-0.537) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.383, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.686) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.748) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.842) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.787) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.425, test=-0.452) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.404, test=-0.528) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.406, test=-0.537) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.383, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.420, test=-0.453) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.406, test=-0.510) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.386, test=-0.572) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.840) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.420, test=-0.453) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.406, test=-0.510) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.386, test=-0.572) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.424, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.403, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.405, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.385, test=-0.559) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.776) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.424, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.403, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.405, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.385, test=-0.559) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.439, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.421, test=-0.539) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.403, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.749) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.847) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.783) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.439, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.421, test=-0.539) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.403, test=-0.556) total time=   0.1s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.436, test=-0.427) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.409, test=-0.547) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.418, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.400, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.677) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.752) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.840) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.780) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.436, test=-0.427) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.409, test=-0.547) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.418, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.400, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.430, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.418, test=-0.534) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.423, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.400, test=-0.545) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.834) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.775) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.430, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.418, test=-0.534) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.423, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.400, test=-0.545) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.429, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.414, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.420, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.401, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.429, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.414, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.420, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.401, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.449, test=-0.429) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.428, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.419, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.674) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.449, test=-0.429) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.428, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.419, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.442, test=-0.425) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.415, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.561) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.670) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.840) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.442, test=-0.425) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.425, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.415, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.404, test=-0.561) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.443, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.430, test=-0.506) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.425, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.408, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.782) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.443, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.430, test=-0.506) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.425, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.408, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.439, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.433, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.422, test=-0.509) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.693) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.825) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.782) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.439, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.433, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.422, test=-0.509) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.465, test=-0.410) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.429, test=-0.506) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.428, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.414, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.672) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.840) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.465, test=-0.410) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.429, test=-0.506) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.428, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.414, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.460, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.503) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.426, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.413, test=-0.544) total time=   0.1s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.672) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.739) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.831) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.777) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.460, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.429, test=-0.503) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.426, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.413, test=-0.544) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.456, test=-0.420) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.430, test=-0.497) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.433, test=-0.512) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.675) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.737) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.823) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.773) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.456, test=-0.420) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.430, test=-0.497) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.433, test=-0.512) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.457, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.440, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.438, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.685) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.823) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.777) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.457, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.440, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.438, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.335, test=-0.711) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.280, test=-0.780) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.310, test=-0.898) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.313, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.823) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.835) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.174, test=-1.006) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.193, test=-0.888) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.335, test=-0.711) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.280, test=-0.780) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.310, test=-0.898) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.313, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.333, test=-0.714) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.311, test=-0.901) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.830) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.829) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.174, test=-1.005) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.193, test=-0.887) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.333, test=-0.714) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.311, test=-0.901) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.333, test=-0.717) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.311, test=-0.890) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.834) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.828) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.174, test=-0.995) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.193, test=-0.888) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.333, test=-0.717) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.311, test=-0.890) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.334, test=-0.718) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.311, test=-0.890) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.837) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.826) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.174, test=-0.995) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.193, test=-0.888) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.334, test=-0.718) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.311, test=-0.890) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.411, test=-0.508) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.377, test=-0.556) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.359, test=-0.636) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.374, test=-0.593) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.717) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.764) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.880) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.411, test=-0.508) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.377, test=-0.556) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.359, test=-0.636) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.374, test=-0.593) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.408, test=-0.510) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.375, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.364, test=-0.629) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.588) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.715) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.765) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.872) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.408, test=-0.510) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.375, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.364, test=-0.629) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.588) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.399, test=-0.499) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.372, test=-0.565) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.362, test=-0.611) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.369, test=-0.588) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.710) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.766) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.856) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.399, test=-0.499) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.372, test=-0.565) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.362, test=-0.611) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.369, test=-0.588) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.400, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.372, test=-0.563) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.361, test=-0.618) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.369, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.708) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.856) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.400, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.372, test=-0.563) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.361, test=-0.618) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.369, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.399, test=-0.551) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.396, test=-0.563) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.762) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.862) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.795) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.399, test=-0.551) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.396, test=-0.563) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.401, test=-0.551) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.399, test=-0.557) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.697) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.855) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.790) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.417, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.401, test=-0.551) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.399, test=-0.557) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.385, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.411, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.403, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.404, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.382, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.788) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.411, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.403, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.404, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.382, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.414, test=-0.457) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.401, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.404, test=-0.537) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.382, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.840) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.793) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.414, test=-0.457) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.401, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.404, test=-0.537) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.382, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.428, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.401, test=-0.531) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.409, test=-0.527) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.387, test=-0.577) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.683) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.756) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.428, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.401, test=-0.531) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.409, test=-0.527) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.387, test=-0.577) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.413, test=-0.519) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.793) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.404, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.413, test=-0.519) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.385, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.419, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.413, test=-0.519) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.414, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.389, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.749) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.419, test=-0.469) total time=   0.2s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.413, test=-0.519) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.414, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.389, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.418, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.411, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.410, test=-0.517) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.387, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.831) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.788) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.418, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.411, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.410, test=-0.517) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.387, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.436, test=-0.429) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.415, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.416, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.402, test=-0.584) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.672) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.754) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.436, test=-0.429) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.415, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.416, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.402, test=-0.584) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.438, test=-0.441) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.415, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.402, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.793) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.438, test=-0.441) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.415, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.417, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.402, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.434, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.418, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.419, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.405, test=-0.562) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.749) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.434, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.418, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.419, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.405, test=-0.562) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.433, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.418, test=-0.529) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.412, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.404, test=-0.574) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.746) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.794) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.433, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.418, test=-0.529) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.412, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.404, test=-0.574) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.450, test=-0.417) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.423, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.408, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.788) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.450, test=-0.417) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.423, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.408, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.442, test=-0.427) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.510) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.420, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.781) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.442, test=-0.427) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.429, test=-0.510) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.420, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.442, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.431, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.409, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.834) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.788) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.442, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.431, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.409, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.438, test=-0.458) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.435, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.422, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.410, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.698) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.737) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.832) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.438, test=-0.458) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.435, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.422, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.410, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.413) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.434, test=-0.501) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.520) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.417, test=-0.540) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.674) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.735) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.839) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.781) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.413) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.434, test=-0.501) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.520) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.417, test=-0.540) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.457, test=-0.412) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.434, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.514) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.414, test=-0.541) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.670) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.778) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.457, test=-0.412) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.434, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.425, test=-0.514) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.414, test=-0.541) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.455, test=-0.431) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.429, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.427, test=-0.500) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.418, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.739) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.819) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.785) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.455, test=-0.431) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.429, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.427, test=-0.500) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.418, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.453, test=-0.444) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.434, test=-0.488) total time=   0.1s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.429, test=-0.504) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.422, test=-0.547) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.692) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.733) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.819) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.782) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.453, test=-0.444) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.434, test=-0.488) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.429, test=-0.504) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.422, test=-0.547) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.335, test=-0.711) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.280, test=-0.780) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.310, test=-0.898) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.313, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.823) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.835) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.174, test=-1.006) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.193, test=-0.888) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.335, test=-0.711) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.280, test=-0.780) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.310, test=-0.898) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.313, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.333, test=-0.714) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.311, test=-0.901) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.830) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.829) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.174, test=-1.005) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.193, test=-0.887) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.333, test=-0.714) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.311, test=-0.901) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.333, test=-0.717) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.311, test=-0.890) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.834) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.828) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.174, test=-0.995) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.193, test=-0.888) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.333, test=-0.717) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.311, test=-0.890) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.334, test=-0.718) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.311, test=-0.890) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.837) total time=   0.1s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.826) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.174, test=-0.995) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.193, test=-0.888) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.334, test=-0.718) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.279, test=-0.775) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.311, test=-0.890) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.318, test=-0.717) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.411, test=-0.508) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.377, test=-0.556) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.359, test=-0.636) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.374, test=-0.593) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.717) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.764) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.880) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.411, test=-0.508) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.377, test=-0.556) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.359, test=-0.636) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.374, test=-0.593) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.408, test=-0.510) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.375, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.364, test=-0.629) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.588) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.715) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.765) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.872) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.408, test=-0.510) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.375, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.364, test=-0.629) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.588) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.399, test=-0.499) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.372, test=-0.565) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.362, test=-0.611) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.369, test=-0.588) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.710) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.766) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.856) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.399, test=-0.499) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.372, test=-0.565) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.362, test=-0.611) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.369, test=-0.588) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.400, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.372, test=-0.563) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.361, test=-0.618) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.369, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.708) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.856) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.400, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.372, test=-0.563) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.361, test=-0.618) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.369, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.399, test=-0.551) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.396, test=-0.563) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.762) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.862) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.795) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.399, test=-0.551) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.396, test=-0.563) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.401, test=-0.551) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.399, test=-0.557) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.697) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.855) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.790) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.417, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.401, test=-0.551) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.399, test=-0.557) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.385, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.411, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.403, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.404, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.382, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.788) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.411, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.403, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.404, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.382, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.414, test=-0.457) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.401, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.404, test=-0.537) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.382, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.840) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.793) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.414, test=-0.457) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.401, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.404, test=-0.537) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.382, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.428, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.401, test=-0.531) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.409, test=-0.527) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.387, test=-0.577) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.683) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.756) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.428, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.401, test=-0.531) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.409, test=-0.527) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.387, test=-0.577) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.413, test=-0.519) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.793) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.404, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.413, test=-0.519) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.385, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.419, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.413, test=-0.519) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.414, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.389, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.749) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.419, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.413, test=-0.519) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.414, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.389, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.418, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.411, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.410, test=-0.517) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.387, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.831) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.788) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.418, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.411, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.410, test=-0.517) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.387, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.436, test=-0.429) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.415, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.416, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.402, test=-0.584) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.672) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.754) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.436, test=-0.429) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.415, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.416, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.402, test=-0.584) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.438, test=-0.441) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.415, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.402, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.793) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.438, test=-0.441) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.415, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.417, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.402, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.434, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.418, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.419, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.405, test=-0.562) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.749) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.434, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.418, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.419, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.405, test=-0.562) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.433, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.418, test=-0.529) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.412, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.404, test=-0.574) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.746) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.794) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.433, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.418, test=-0.529) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.412, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.404, test=-0.574) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.450, test=-0.417) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.423, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.408, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.788) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.450, test=-0.417) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.423, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.408, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.442, test=-0.427) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.510) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.420, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.781) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.442, test=-0.427) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.429, test=-0.510) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.420, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.442, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.431, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.409, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.1s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.834) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.788) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.442, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.431, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.529) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.409, test=-0.557) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.438, test=-0.458) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.435, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.422, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.410, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.698) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.737) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.832) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.438, test=-0.458) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.435, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.422, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.410, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.413) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.434, test=-0.501) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.520) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.417, test=-0.540) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.674) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.735) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.839) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.781) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.413) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.434, test=-0.501) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.520) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.417, test=-0.540) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.457, test=-0.412) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.434, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.514) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.414, test=-0.541) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.670) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.778) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.457, test=-0.412) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.434, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.425, test=-0.514) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.414, test=-0.541) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.455, test=-0.431) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.429, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.427, test=-0.500) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.418, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.739) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.819) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.785) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.455, test=-0.431) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.429, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.427, test=-0.500) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.418, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.453, test=-0.444) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.434, test=-0.488) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.429, test=-0.504) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.422, test=-0.547) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.692) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.733) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.819) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.782) total time=   0.0s\n",
      "[CV 1/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.453, test=-0.444) total time=   0.0s\n",
      "[CV 2/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.434, test=-0.488) total time=   0.0s\n",
      "[CV 3/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.429, test=-0.504) total time=   0.0s\n",
      "[CV 4/4] END algorithm=ball_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.422, test=-0.547) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.342, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.283, test=-0.756) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.304, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.325, test=-0.692) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.237, test=-0.811) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-0.954) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.860) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.342, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.283, test=-0.756) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.304, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.325, test=-0.692) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.341, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.282, test=-0.756) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.304, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.318, test=-0.692) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.237, test=-0.812) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.835) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-0.949) total time=   0.2s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.860) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.341, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.282, test=-0.756) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.304, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.318, test=-0.692) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.341, test=-0.713) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.282, test=-0.756) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.304, test=-0.810) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.318, test=-0.693) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.237, test=-0.821) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.833) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.931) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.860) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.341, test=-0.713) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.282, test=-0.756) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.304, test=-0.810) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.318, test=-0.693) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.341, test=-0.713) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.282, test=-0.754) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.304, test=-0.810) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.318, test=-0.693) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.237, test=-0.821) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.830) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.930) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.860) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.341, test=-0.713) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.282, test=-0.754) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.304, test=-0.810) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.318, test=-0.693) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.410, test=-0.529) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.383, test=-0.555) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.376, test=-0.591) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.378, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.728) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.858) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.410, test=-0.529) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.383, test=-0.555) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.376, test=-0.591) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.378, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.528) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.383, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.374, test=-0.587) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.378, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.730) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.764) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.815) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.410, test=-0.528) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.383, test=-0.561) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.374, test=-0.587) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.378, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.401, test=-0.530) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.379, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.374, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.374, test=-0.601) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.732) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.762) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.814) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.401, test=-0.530) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.379, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.374, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.374, test=-0.601) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.402, test=-0.530) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.379, test=-0.556) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.374, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.374, test=-0.601) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.733) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.758) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.813) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.402, test=-0.530) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.379, test=-0.556) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.374, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.374, test=-0.601) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.414, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.403, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.396, test=-0.548) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.385, test=-0.598) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.697) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.755) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.854) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.414, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.403, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.396, test=-0.548) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.385, test=-0.598) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.415, test=-0.478) total time=   0.2s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.400, test=-0.537) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.398, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.384, test=-0.600) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.705) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.759) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.848) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.818) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.415, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.400, test=-0.537) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.398, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.384, test=-0.600) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.409, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.397, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.395, test=-0.532) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.380, test=-0.598) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.705) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.815) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.409, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.397, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.395, test=-0.532) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.380, test=-0.598) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.408, test=-0.479) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.397, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.395, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.380, test=-0.599) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.748) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.842) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.815) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.408, test=-0.479) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.397, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.395, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.380, test=-0.599) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.426, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.408, test=-0.531) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.416, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.391, test=-0.583) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.821) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.426, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.408, test=-0.531) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.416, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.391, test=-0.583) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.424, test=-0.468) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.406, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.416, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.392, test=-0.583) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.692) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.752) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.820) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.424, test=-0.468) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.406, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.416, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.392, test=-0.583) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.422, test=-0.468) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.408, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.413, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.392, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.845) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.818) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.422, test=-0.468) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.408, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.413, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.392, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.421, test=-0.468) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.407, test=-0.511) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.413, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.392, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.819) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.421, test=-0.468) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.407, test=-0.511) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.413, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.392, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.436, test=-0.431) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.411, test=-0.541) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.412, test=-0.520) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.405, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.436, test=-0.431) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.411, test=-0.541) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.412, test=-0.520) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.405, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.438, test=-0.438) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.408, test=-0.539) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.834) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.438, test=-0.438) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.408, test=-0.539) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.410, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.404, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.433, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.416, test=-0.536) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.413, test=-0.520) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.403, test=-0.561) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.746) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.831) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.433, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.416, test=-0.536) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.413, test=-0.520) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.403, test=-0.561) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.433, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.415, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.409, test=-0.516) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.403, test=-0.561) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.433, test=-0.455) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.415, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.409, test=-0.516) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.403, test=-0.561) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.448, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.425, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.403, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.674) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.746) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.846) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.448, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.425, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.403, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.445, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.423, test=-0.532) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.405, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.840) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.445, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.422, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.423, test=-0.532) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.405, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.443, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.430, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.408, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.799) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.443, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.430, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.408, test=-0.564) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.442, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.429, test=-0.508) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.427, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.412, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.692) total time=   0.1s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.442, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.429, test=-0.508) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.427, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.412, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.461, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.429, test=-0.508) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.433, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.413, test=-0.562) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.675) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.842) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.461, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.429, test=-0.508) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.433, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.413, test=-0.562) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.458, test=-0.420) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.430, test=-0.502) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.431, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.411, test=-0.561) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.675) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.834) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.458, test=-0.420) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.430, test=-0.502) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.431, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.411, test=-0.561) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.458, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.432, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.433, test=-0.519) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.417, test=-0.563) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.684) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.741) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.828) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.458, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.432, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.433, test=-0.519) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.417, test=-0.563) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.457, test=-0.445) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.437, test=-0.491) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.436, test=-0.514) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.419, test=-0.559) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.693) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.824) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.795) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.457, test=-0.445) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.437, test=-0.491) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.436, test=-0.514) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.419, test=-0.559) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.330, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.287, test=-0.767) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.301, test=-0.847) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.311, test=-0.704) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.232, test=-0.799) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.183, test=-0.843) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-0.967) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.873) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.330, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.287, test=-0.767) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.301, test=-0.847) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.311, test=-0.704) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.329, test=-0.705) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.287, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.300, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.311, test=-0.704) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.232, test=-0.802) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.183, test=-0.845) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-0.960) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.872) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.329, test=-0.705) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.287, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.300, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.311, test=-0.704) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.329, test=-0.714) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.286, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.300, test=-0.825) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.311, test=-0.705) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.232, test=-0.810) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.183, test=-0.845) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.942) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.872) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.329, test=-0.714) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.286, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.300, test=-0.825) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.311, test=-0.705) total time=   0.1s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.330, test=-0.714) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.286, test=-0.769) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.300, test=-0.825) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.311, test=-0.705) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.232, test=-0.811) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.183, test=-0.842) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.941) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.872) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.330, test=-0.714) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.286, test=-0.769) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.300, test=-0.825) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.311, test=-0.705) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.411, test=-0.514) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.374, test=-0.563) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.374, test=-0.607) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.382, test=-0.611) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.723) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.762) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.862) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.822) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.411, test=-0.514) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.374, test=-0.563) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.374, test=-0.607) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.382, test=-0.611) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.514) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.373, test=-0.562) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.374, test=-0.606) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.381, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.726) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.857) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.819) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.410, test=-0.514) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.373, test=-0.562) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.374, test=-0.606) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.381, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.403, test=-0.519) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.373, test=-0.568) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.374, test=-0.600) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.380, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.727) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.768) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.819) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.403, test=-0.519) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.373, test=-0.568) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.374, test=-0.600) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.380, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.403, test=-0.519) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.370, test=-0.565) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.374, test=-0.601) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.380, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.728) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.765) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.819) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.403, test=-0.519) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.370, test=-0.565) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.374, test=-0.601) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.380, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.421, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.400, test=-0.529) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.393, test=-0.539) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.390, test=-0.590) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.752) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.853) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.811) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.421, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.400, test=-0.529) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.393, test=-0.539) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.390, test=-0.590) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.419, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.398, test=-0.531) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.395, test=-0.544) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.388, test=-0.591) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.811) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.419, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.398, test=-0.531) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.395, test=-0.544) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.388, test=-0.591) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.415, test=-0.466) total time=   0.2s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.395, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.392, test=-0.535) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.386, test=-0.589) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.415, test=-0.466) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.395, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.392, test=-0.535) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.386, test=-0.589) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.415, test=-0.466) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.394, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.391, test=-0.532) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.384, test=-0.590) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.415, test=-0.466) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.394, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.391, test=-0.532) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.384, test=-0.590) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.429, test=-0.436) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.404, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.405, test=-0.548) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.391, test=-0.588) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.855) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.816) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.429, test=-0.436) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.404, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.405, test=-0.548) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.391, test=-0.588) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.409, test=-0.528) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.406, test=-0.545) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.390, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.685) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.814) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.425, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.409, test=-0.528) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.406, test=-0.545) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.390, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.422, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.409, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.405, test=-0.540) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.393, test=-0.586) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.684) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.739) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.847) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.813) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.422, test=-0.448) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.409, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.405, test=-0.540) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.393, test=-0.586) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.420, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.406, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.405, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.392, test=-0.586) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.682) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.737) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.812) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.420, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.406, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.405, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.392, test=-0.586) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.431, test=-0.424) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.415, test=-0.539) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.417, test=-0.512) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.404, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.677) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.746) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.834) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.431, test=-0.424) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.415, test=-0.539) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.417, test=-0.512) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.404, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.431, test=-0.437) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.411, test=-0.531) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.420, test=-0.509) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.405, test=-0.572) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.805) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.431, test=-0.437) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.411, test=-0.531) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.420, test=-0.509) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.405, test=-0.572) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.431, test=-0.446) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.417, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.422, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.404, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.732) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.827) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.431, test=-0.446) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.417, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.422, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.404, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.430, test=-0.451) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.418, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.418, test=-0.507) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.405, test=-0.571) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.734) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.823) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.804) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.430, test=-0.451) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.418, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.418, test=-0.507) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.405, test=-0.571) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.450, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.425, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.414, test=-0.545) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.411, test=-0.570) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.675) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.746) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.848) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.450, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.425, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.414, test=-0.545) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.411, test=-0.570) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.447, test=-0.425) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.424, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.415, test=-0.545) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.411, test=-0.571) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.674) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.447, test=-0.425) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.424, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.415, test=-0.545) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.411, test=-0.571) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.443, test=-0.452) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.428, test=-0.511) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.420, test=-0.539) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.414, test=-0.567) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.798) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.443, test=-0.452) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.428, test=-0.511) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.420, test=-0.539) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.414, test=-0.567) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.443, test=-0.456) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.433, test=-0.500) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.418, test=-0.540) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.416, test=-0.567) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.697) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.832) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.443, test=-0.456) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.433, test=-0.500) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.418, test=-0.540) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.416, test=-0.567) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.410) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.430, test=-0.510) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.424, test=-0.527) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.414, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.671) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.1s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.410) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.430, test=-0.510) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.424, test=-0.527) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.414, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.460, test=-0.413) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.433, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.424, test=-0.517) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.412, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.671) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.831) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.788) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.460, test=-0.413) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.433, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.424, test=-0.517) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.412, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.456, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.434, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.428, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.420, test=-0.549) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.824) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.456, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.434, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.428, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.420, test=-0.549) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.457, test=-0.440) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.441, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.429, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.421, test=-0.549) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.735) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.820) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.457, test=-0.440) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.441, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.429, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.421, test=-0.549) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.332, test=-0.722) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.283, test=-0.761) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.304, test=-0.856) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.318, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.827) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.836) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.174, test=-0.969) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.193, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.332, test=-0.722) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.283, test=-0.761) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.304, test=-0.856) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.318, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.329, test=-0.725) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.304, test=-0.848) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.323, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.832) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.834) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.174, test=-0.958) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.193, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.329, test=-0.725) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.304, test=-0.848) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.323, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.329, test=-0.733) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.304, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.323, test=-0.723) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.840) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.833) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.174, test=-0.946) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.193, test=-0.880) total time=   0.1s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.329, test=-0.733) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.304, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.323, test=-0.723) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.330, test=-0.733) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.304, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.323, test=-0.723) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.841) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.832) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.174, test=-0.945) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.193, test=-0.881) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.330, test=-0.733) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.304, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.323, test=-0.723) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.411, test=-0.507) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.375, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.363, test=-0.612) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.379, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.718) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.761) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.814) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.411, test=-0.507) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.375, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.363, test=-0.612) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.379, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.408, test=-0.509) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.564) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.368, test=-0.609) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.376, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.766) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.861) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.807) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.408, test=-0.509) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.564) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.368, test=-0.609) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.376, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.400, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.565) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.603) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.373, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.711) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.765) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.854) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.400, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.565) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.603) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.373, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.401, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.365, test=-0.563) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.366, test=-0.604) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.373, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.762) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.854) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.401, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.365, test=-0.563) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.366, test=-0.604) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.373, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.400, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.399, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.394, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.698) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.754) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.856) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.812) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.400, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.399, test=-0.541) total time=   0.1s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.394, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.418, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.399, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.403, test=-0.543) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.392, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.697) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.757) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.811) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.418, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.399, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.403, test=-0.543) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.392, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.412, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.399, test=-0.537) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.401, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.391, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.697) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.754) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.412, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.399, test=-0.537) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.401, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.391, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.413, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.398, test=-0.534) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.400, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.390, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.413, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.398, test=-0.534) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.400, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.390, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.430, test=-0.452) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.407, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.417, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.430, test=-0.452) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.407, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.417, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.419, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.409, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.421, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.692) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.799) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.419, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.409, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.421, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.416, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.413, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.417, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.398, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.416, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.413, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.417, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.398, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.414, test=-0.464) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.411, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.416, test=-0.508) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.414, test=-0.464) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.411, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.416, test=-0.508) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.429, test=-0.427) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.415, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.415, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.402, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.746) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.807) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.429, test=-0.427) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.415, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.415, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.402, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.431, test=-0.436) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.414, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.414, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.682) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.431, test=-0.436) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.414, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.414, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.404, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.426, test=-0.458) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.420, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.416, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.406, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.741) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.832) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.805) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.426, test=-0.458) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.420, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.416, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.406, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.427, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.418, test=-0.520) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.413, test=-0.532) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.405, test=-0.579) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.692) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.427, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.418, test=-0.520) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.413, test=-0.532) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.405, test=-0.579) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.449, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.426, test=-0.528) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.422, test=-0.542) total time=   0.1s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.407, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.680) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.848) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.803) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.449, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.426, test=-0.528) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.422, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.407, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.442, test=-0.432) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.406, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.840) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.803) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.442, test=-0.432) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.425, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.422, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.406, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.441, test=-0.457) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.429, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.425, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.410, test=-0.577) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.699) total time=   0.1s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.1s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.834) total time=   0.1s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.441, test=-0.457) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.429, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.425, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.410, test=-0.577) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.441, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.432, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.424, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.412, test=-0.579) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.703) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.739) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.804) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.441, test=-0.463) total time=   0.1s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.432, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.424, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.412, test=-0.579) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.464, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.435, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.420, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.677) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.839) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.805) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.464, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.435, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.420, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.456, test=-0.420) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.434, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.426, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.559) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.737) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.832) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.456, test=-0.420) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.434, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.426, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.417, test=-0.559) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.453, test=-0.442) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.430, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.429, test=-0.516) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.421, test=-0.558) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.739) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.826) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.453, test=-0.442) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.430, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.429, test=-0.516) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.421, test=-0.558) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.452, test=-0.449) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.437, test=-0.490) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.431, test=-0.511) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.424, test=-0.558) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.735) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.820) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.452, test=-0.449) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.437, test=-0.490) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.431, test=-0.511) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.424, test=-0.558) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.332, test=-0.722) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.283, test=-0.761) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.304, test=-0.856) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.318, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.827) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.836) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.174, test=-0.969) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.193, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.332, test=-0.722) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.283, test=-0.761) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.304, test=-0.856) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.318, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.329, test=-0.725) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.304, test=-0.848) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.323, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.832) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.834) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.174, test=-0.958) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.193, test=-0.880) total time=   0.1s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.329, test=-0.725) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.304, test=-0.848) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.323, test=-0.722) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.329, test=-0.733) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.304, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.323, test=-0.723) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.840) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.833) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.174, test=-0.946) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.193, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.329, test=-0.733) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.304, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.323, test=-0.723) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.330, test=-0.733) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.304, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.323, test=-0.723) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.841) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.832) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.174, test=-0.945) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.193, test=-0.881) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.330, test=-0.733) total time=   0.2s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.282, test=-0.763) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.304, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.323, test=-0.723) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.411, test=-0.507) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.375, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.363, test=-0.612) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.379, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.718) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.761) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.814) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.411, test=-0.507) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.375, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.363, test=-0.612) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.379, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.408, test=-0.509) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.564) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.368, test=-0.609) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.376, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.766) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.861) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.807) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.408, test=-0.509) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.564) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.368, test=-0.609) total time=   0.1s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.376, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.400, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.565) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.603) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.373, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.711) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.765) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.854) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.400, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.565) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.603) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.373, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.401, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.365, test=-0.563) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.366, test=-0.604) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.373, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.762) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.854) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.401, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.365, test=-0.563) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.366, test=-0.604) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.373, test=-0.602) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.400, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.399, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.394, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.698) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.754) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.856) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.812) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.463) total time=   0.1s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.400, test=-0.543) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.399, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.394, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.418, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.399, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.403, test=-0.543) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.392, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.697) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.757) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.811) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.418, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.399, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.403, test=-0.543) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.392, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.412, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.399, test=-0.537) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.401, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.391, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.697) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.754) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.412, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.399, test=-0.537) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.401, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.391, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.413, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.398, test=-0.534) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.400, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.390, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.413, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.398, test=-0.534) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.400, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.390, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.430, test=-0.452) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.407, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.417, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.430, test=-0.452) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.407, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.417, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.419, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.409, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.421, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.692) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.799) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.419, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.409, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.421, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.416, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.413, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.417, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.398, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.2s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.416, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.413, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.417, test=-0.513) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.398, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.414, test=-0.464) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.411, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.416, test=-0.508) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.690) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.414, test=-0.464) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.411, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.416, test=-0.508) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.396, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.429, test=-0.427) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.415, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.415, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.402, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.746) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.843) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.807) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.429, test=-0.427) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.415, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.415, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.402, test=-0.582) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.431, test=-0.436) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.414, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.414, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.682) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.431, test=-0.436) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.414, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.414, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.404, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.426, test=-0.458) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.420, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.416, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.406, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.741) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.832) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.805) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.426, test=-0.458) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.420, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.416, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.406, test=-0.578) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.427, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.418, test=-0.520) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.413, test=-0.532) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.405, test=-0.579) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.692) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.740) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.427, test=-0.460) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.418, test=-0.520) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.413, test=-0.532) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.405, test=-0.579) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.449, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.426, test=-0.528) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.422, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.407, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.680) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.848) total time=   0.2s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.803) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.449, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.426, test=-0.528) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.422, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.407, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.442, test=-0.432) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.406, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.840) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.803) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.442, test=-0.432) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.425, test=-0.512) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.422, test=-0.533) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.406, test=-0.580) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.441, test=-0.457) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.429, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.425, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.410, test=-0.577) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.699) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.834) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.441, test=-0.457) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.429, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.425, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.410, test=-0.577) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.441, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.432, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.424, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.412, test=-0.579) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.703) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.739) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.804) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.441, test=-0.463) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.432, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.424, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.412, test=-0.579) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.464, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.435, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.420, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.677) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.839) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.805) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.464, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.435, test=-0.504) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.528) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.420, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.456, test=-0.420) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.434, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.426, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.559) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.737) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.832) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.456, test=-0.420) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.434, test=-0.498) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.426, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.417, test=-0.559) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.453, test=-0.442) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.430, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.429, test=-0.516) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.421, test=-0.558) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.2s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.739) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.826) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.453, test=-0.442) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.430, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.429, test=-0.516) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.421, test=-0.558) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.452, test=-0.449) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.437, test=-0.490) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.431, test=-0.511) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.424, test=-0.558) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.735) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.820) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.452, test=-0.449) total time=   0.0s\n",
      "[CV 2/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.437, test=-0.490) total time=   0.0s\n",
      "[CV 3/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.431, test=-0.511) total time=   0.0s\n",
      "[CV 4/4] END algorithm=kd_tree, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.424, test=-0.558) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.820) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.868) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-0.959) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.881) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.821) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-0.952) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.827) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.864) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.828) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.706) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.842) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.738) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.769) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.818) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.732) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.831) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.863) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.854) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.758) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.1s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.752) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.809) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.846) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.703) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.827) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.408, test=-0.496) total time=   0.2s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.680) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.755) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.853) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.810) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.2s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.686) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.413, test=-0.550) total time=   0.1s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.787) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.821) total time=   0.1s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.778) total time=   0.1s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.679) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.818) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.816) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=10, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.820) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.868) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-0.959) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.881) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.821) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-0.952) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.827) total time=   0.1s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.864) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.828) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.706) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.842) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.738) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.769) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.818) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.732) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.831) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.863) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.854) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.758) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.752) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.809) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.846) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.516) total time=   0.2s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.703) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.827) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.680) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.755) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.853) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.810) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.686) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.1s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.787) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.821) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.778) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.679) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.818) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.816) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=30, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.820) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.868) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-0.959) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.881) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.821) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-0.952) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.827) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.864) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.828) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.706) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.842) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.738) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.769) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.818) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.732) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.831) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.385, test=-0.576) total time=   0.2s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.863) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.854) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.758) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.752) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.809) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.846) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.703) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.827) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.680) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.755) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.853) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.810) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.686) total time=   0.2s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.787) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.464, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.412, test=-0.554) total time=   0.2s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.1s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.1s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.821) total time=   0.1s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.778) total time=   0.1s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.464, test=-0.407) total time=   0.1s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.679) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.818) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.816) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=50, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=uniform;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.236, test=-0.820) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.181, test=-0.868) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.172, test=-0.959) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=distance;, score=(train=-0.199, test=-0.881) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.348, test=-0.772) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.307, test=-0.849) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.297, test=-0.867) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1, weights=None;, score=(train=-0.337, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=uniform;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.236, test=-0.821) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.172, test=-0.952) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.353, test=-0.770) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.306, test=-0.838) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.296, test=-0.852) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=1.5, weights=None;, score=(train=-0.344, test=-0.714) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.236, test=-0.827) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.181, test=-0.864) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.353, test=-0.776) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.306, test=-0.839) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=2, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=uniform;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.236, test=-0.828) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.181, test=-0.863) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.172, test=-0.943) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=distance;, score=(train=-0.199, test=-0.880) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.353, test=-0.777) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.306, test=-0.837) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.296, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=2, p=3, weights=None;, score=(train=-0.340, test=-0.715) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=uniform;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.210, test=-0.706) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.156, test=-0.851) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=distance;, score=(train=-0.168, test=-0.842) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.418, test=-0.500) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.404, test=-0.553) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.367, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1, weights=None;, score=(train=-0.376, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=uniform;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.210, test=-0.738) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.161, test=-0.769) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.156, test=-0.849) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=distance;, score=(train=-0.168, test=-0.818) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.417, test=-0.523) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.397, test=-0.575) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.379, test=-0.575) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=1.5, weights=None;, score=(train=-0.372, test=-0.621) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=uniform;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.210, test=-0.732) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.161, test=-0.771) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.156, test=-0.844) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=distance;, score=(train=-0.168, test=-0.831) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.402, test=-0.538) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.399, test=-0.559) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.388, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=2, weights=None;, score=(train=-0.366, test=-0.630) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.372, test=-0.595) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=uniform;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.161, test=-0.774) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.156, test=-0.863) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=distance;, score=(train=-0.168, test=-0.854) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.400, test=-0.489) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.385, test=-0.576) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.372, test=-0.595) total time=   0.2s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=5, p=3, weights=None;, score=(train=-0.369, test=-0.640) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=uniform;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.161, test=-0.760) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.156, test=-0.838) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.422, test=-0.471) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.415, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.401, test=-0.549) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1, weights=None;, score=(train=-0.390, test=-0.594) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=uniform;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.161, test=-0.758) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.422, test=-0.478) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.425, test=-0.535) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.403, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=1.5, weights=None;, score=(train=-0.385, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=uniform;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.210, test=-0.716) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=distance;, score=(train=-0.168, test=-0.817) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.409, test=-0.497) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.416, test=-0.544) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.406, test=-0.559) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=2, weights=None;, score=(train=-0.380, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=uniform;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.210, test=-0.700) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.161, test=-0.752) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=distance;, score=(train=-0.168, test=-0.809) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.405, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.412, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.397, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=7, p=3, weights=None;, score=(train=-0.385, test=-0.597) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=uniform;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.210, test=-0.695) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.161, test=-0.751) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.156, test=-0.846) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=distance;, score=(train=-0.168, test=-0.806) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.430, test=-0.473) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.416, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.406, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1, weights=None;, score=(train=-0.396, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.422, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=uniform;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.210, test=-0.702) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.161, test=-0.747) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=distance;, score=(train=-0.168, test=-0.786) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.429, test=-0.469) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.422, test=-0.516) total time=   0.2s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.410, test=-0.525) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=1.5, weights=None;, score=(train=-0.389, test=-0.555) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=uniform;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.210, test=-0.703) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.156, test=-0.827) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=distance;, score=(train=-0.168, test=-0.801) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.420, test=-0.462) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.417, test=-0.533) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.407, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=2, weights=None;, score=(train=-0.385, test=-0.581) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=uniform;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.210, test=-0.694) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.156, test=-0.829) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=distance;, score=(train=-0.168, test=-0.796) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.416, test=-0.454) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.408, test=-0.496) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.403, test=-0.536) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=8, p=3, weights=None;, score=(train=-0.387, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=uniform;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.210, test=-0.680) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.161, test=-0.755) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.156, test=-0.853) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=distance;, score=(train=-0.168, test=-0.808) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.451, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.431, test=-0.514) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.410, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1, weights=None;, score=(train=-0.403, test=-0.585) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=uniform;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.210, test=-0.704) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.161, test=-0.753) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.156, test=-0.841) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=distance;, score=(train=-0.168, test=-0.784) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.447, test=-0.461) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.429, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.417, test=-0.538) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=1.5, weights=None;, score=(train=-0.393, test=-0.556) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=uniform;, score=(train=-0.399, test=-0.569) total time=   0.1s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.210, test=-0.687) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.156, test=-0.836) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=distance;, score=(train=-0.168, test=-0.797) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.448, test=-0.433) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.432, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.420, test=-0.541) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=2, weights=None;, score=(train=-0.399, test=-0.569) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=uniform;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.210, test=-0.691) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.161, test=-0.738) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.156, test=-0.837) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=distance;, score=(train=-0.168, test=-0.810) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.439, test=-0.447) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.424, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.413, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=10, p=3, weights=None;, score=(train=-0.401, test=-0.587) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=uniform;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.210, test=-0.676) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.161, test=-0.750) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.156, test=-0.850) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.449, test=-0.414) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.431, test=-0.513) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.417, test=-0.547) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1, weights=None;, score=(train=-0.404, test=-0.565) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=uniform;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.210, test=-0.686) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.451, test=-0.430) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.432, test=-0.492) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.427, test=-0.524) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=1.5, weights=None;, score=(train=-0.404, test=-0.566) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=uniform;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.210, test=-0.688) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.156, test=-0.833) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=distance;, score=(train=-0.168, test=-0.800) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.450, test=-0.435) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.439, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.426, test=-0.523) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=2, weights=None;, score=(train=-0.406, test=-0.568) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.429, test=-0.494) total time=   0.1s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=uniform;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.210, test=-0.696) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.161, test=-0.736) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.156, test=-0.830) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=distance;, score=(train=-0.168, test=-0.802) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.452, test=-0.450) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.429, test=-0.494) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.426, test=-0.526) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=12, p=3, weights=None;, score=(train=-0.411, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=uniform;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.210, test=-0.681) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.161, test=-0.745) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.156, test=-0.835) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=distance;, score=(train=-0.168, test=-0.787) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.463, test=-0.419) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.437, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.427, test=-0.521) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1, weights=None;, score=(train=-0.413, test=-0.550) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.464, test=-0.407) total time=   0.1s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.443, test=-0.505) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=uniform;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.210, test=-0.673) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.161, test=-0.742) total time=   0.1s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.156, test=-0.821) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=distance;, score=(train=-0.168, test=-0.778) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.464, test=-0.407) total time=   0.1s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.443, test=-0.505) total time=   0.1s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.428, test=-0.503) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=1.5, weights=None;, score=(train=-0.412, test=-0.554) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.210, test=-0.679) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.161, test=-0.743) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.156, test=-0.818) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=distance;, score=(train=-0.168, test=-0.791) total time=   0.1s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.463, test=-0.422) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.444, test=-0.499) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.427, test=-0.510) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=2, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.432, test=-0.515) total time=   0.2s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=uniform;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.210, test=-0.689) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.161, test=-0.744) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.156, test=-0.816) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=distance;, score=(train=-0.168, test=-0.789) total time=   0.0s\n",
      "[CV 1/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.461, test=-0.434) total time=   0.0s\n",
      "[CV 2/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.440, test=-0.509) total time=   0.0s\n",
      "[CV 3/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.432, test=-0.515) total time=   0.0s\n",
      "[CV 4/4] END algorithm=brute, leaf_size=75, n_jobs=-1, n_neighbors=15, p=3, weights=None;, score=(train=-0.421, test=-0.560) total time=   0.0s\n",
      "-0.4911107783434826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "grid_params3 = {\n",
    "    \"n_neighbors\" : [2,5,7,8,10,12,15],\n",
    "    \"weights\" : [\"uniform\", \"distance\", None],\n",
    "    \"algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    \"leaf_size\" : [10,30,50,75],\n",
    "    \"p\": [1, 1.5, 2,3],\n",
    "    \"n_jobs\": [-1]\n",
    "}\n",
    "\n",
    "knncv = GridSearchCV(knn, grid_params3, scoring=\"neg_mean_squared_error\", cv=4, refit=True, verbose=7, return_train_score=True, error_score='raise')\n",
    "knncv.fit(X_train, y_train)\n",
    "print(knncv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7c159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 560 candidates, totalling 2240 fits\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.519, test=-0.395) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.00112e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.08712e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.5793e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.472, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.479, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.458, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.519, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.472, test=-0.521) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.98231e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22632e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.51947e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.77482e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.58936e-18): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82955e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.10395e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.085e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.21522e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.479, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.475, test=-0.379) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.417, test=-0.564) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.455, test=-0.453) total time=   0.6s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.411, test=-0.573) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.00112e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.08712e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.5793e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.477, test=-0.379) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.420, test=-0.546) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.98231e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22632e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.51947e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.77482e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.58936e-18): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82955e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.10395e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.085e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.21522e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.463) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.413, test=-0.574) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.458, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.406, test=-0.834) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.00112e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.08712e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.5793e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.431, test=-0.488) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.403, test=-0.558) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.460, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.407, test=-0.821) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.98231e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22632e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.51947e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.77482e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.58936e-18): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82955e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.10395e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.085e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.21522e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.433, test=-0.489) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.404, test=-0.558) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.455, test=-0.400) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.403, test=-2.624) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.426, test=-0.509) total time=   0.3s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.401, test=-0.557) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.00112e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.08712e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.5793e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.98231e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22632e-21): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.455, test=-0.399) total time=   0.8s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.403, test=-2.461) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.51947e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.77482e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.58936e-18): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82955e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.10395e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.085e-21): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.426, test=-0.507) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.400, test=-0.554) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.21522e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.397) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.403, test=-3.275) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.426, test=-0.508) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.552) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.00112e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.08712e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.5793e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.98231e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22632e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.51947e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.77482e-23): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.396) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.403, test=-3.064) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.58936e-18): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82955e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.10395e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.085e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.21522e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.426, test=-0.509) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.401, test=-0.552) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.402, test=-1.661) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.425, test=-0.514) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.549) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.00112e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.08712e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.5793e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.98231e-22): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.394) total time=   0.4s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.402, test=-1.661) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22632e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.51947e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.77482e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.58936e-18): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82955e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.10395e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.085e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.425, test=-0.514) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.400, test=-0.549) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.21522e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.455, test=-0.398) total time=   0.9s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.402, test=-1.726) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.425, test=-0.508) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.552) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.00112e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.08712e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.5793e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.98231e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22632e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.51947e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.77482e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.58936e-18): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.455, test=-0.398) total time=   0.3s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.402, test=-1.726) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82955e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.10395e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.085e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.21522e-22): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.425, test=-0.508) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.400, test=-0.552) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.399) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.402, test=-1.726) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.425, test=-0.508) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.552) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.00112e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.08712e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.5793e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.98231e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22632e-21): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.402, test=-1.726) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.51947e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.77482e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.58936e-18): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82955e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.10395e-21): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.425, test=-0.508) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.400, test=-0.552) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.085e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.21522e-22): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.402, test=-1.726) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.425, test=-0.508) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.552) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.00112e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.08712e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.5793e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.98231e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22632e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.51947e-22): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.402, test=-1.726) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.77482e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.58936e-18): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82955e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.10395e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.085e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.21522e-22): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.425, test=-0.508) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.400, test=-0.552) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.399) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.402, test=-1.726) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.425, test=-0.508) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.552) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.00112e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.08712e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.5793e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.98231e-22): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.402, test=-1.726) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22632e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.51947e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.77482e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.58936e-18): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82955e-21): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.425, test=-0.508) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.10395e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.085e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.21522e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.400, test=-0.552) total time=   0.6s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.559, test=-0.409) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.504) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.485, test=-0.648) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.559, test=-0.409) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.525, test=-0.504) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.485, test=-0.648) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.392) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.544) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.489, test=-0.489) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.438, test=-0.585) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.536, test=-0.402) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.493, test=-0.531) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.506, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.379) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.414, test=-0.570) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.449, test=-0.468) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.410, test=-0.558) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.471, test=-0.377) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.415, test=-0.568) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.450, test=-0.465) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.411, test=-0.561) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.456, test=-0.392) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.404, test=-0.881) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.429, test=-0.493) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.554) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.393) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.404, test=-0.879) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.430, test=-0.495) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.401, test=-0.553) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.456, test=-0.411) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.404, test=-1.057) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.428, test=-0.500) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.553) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.410) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.404, test=-0.906) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.428, test=-0.501) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.400, test=-0.553) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.455, test=-0.397) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.402, test=-4.287) total time=   0.7s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.425, test=-0.511) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.550) total time=   0.2s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.455, test=-0.397) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.402, test=-4.404) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.425, test=-0.511) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.401, test=-0.549) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.398) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.402, test=-1.975) total time=   0.3s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.425, test=-0.507) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.552) total time=   0.2s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.398) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.402, test=-1.981) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.425, test=-0.509) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.iteration += _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.400, test=-0.552) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.398) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.402, test=-1.916) total time=   0.2s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.425, test=-0.509) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.552) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.398) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.402, test=-1.916) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.425, test=-0.509) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.400, test=-0.552) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.398) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.402, test=-1.916) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.425, test=-0.509) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.552) total time=   0.5s\n",
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.398) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.402, test=-1.916) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.425, test=-0.509) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.400, test=-0.552) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.398) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.402, test=-1.916) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.425, test=-0.509) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.400, test=-0.552) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=8.15696e-22): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.398) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.402, test=-1.916) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.75815e-24): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.60589e-21): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.425, test=-0.509) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.50263e-19): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.400, test=-0.552) total time=   0.3s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.473, test=-0.519) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.480, test=-0.473) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.605) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.374) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.429, test=-0.531) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.465) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.421, test=-0.571) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.376) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.436, test=-0.518) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.461, test=-0.458) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.426, test=-0.582) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.484, test=-0.375) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.433, test=-0.518) total time=   0.2s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.457) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.423, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.484, test=-0.375) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.434, test=-0.519) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.455) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.423, test=-0.574) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.484, test=-0.375) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.433, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.457) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.423, test=-0.575) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.484, test=-0.375) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.433, test=-0.519) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.457) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.423, test=-0.575) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.484, test=-0.375) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.433, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.457) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.423, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.484, test=-0.375) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.433, test=-0.518) total time=   0.4s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.457) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.423, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.484, test=-0.375) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.433, test=-0.518) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.457) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.423, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.484, test=-0.375) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.433, test=-0.518) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.457) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.423, test=-0.575) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.484, test=-0.375) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.433, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.457) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.423, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.484, test=-0.375) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.433, test=-0.518) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.457) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.423, test=-0.575) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.484, test=-0.375) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.433, test=-0.518) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.457) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.423, test=-0.575) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.484, test=-0.375) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.433, test=-0.518) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.457) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.423, test=-0.575) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.484, test=-0.375) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.433, test=-0.518) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.457) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.423, test=-0.575) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.484, test=-0.375) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.433, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.457) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.423, test=-0.575) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.484, test=-0.375) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.433, test=-0.518) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.457) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.423, test=-0.575) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.484, test=-0.375) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.433, test=-0.518) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.457) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.423, test=-0.575) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.484, test=-0.375) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.433, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.457) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.423, test=-0.575) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.551, test=-0.406) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.538) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.504) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.485, test=-0.647) total time=   0.3s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.564, test=-0.449) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.610) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.521) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.503, test=-0.638) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.517, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.469, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.492, test=-0.489) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.453, test=-0.592) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.429, test=-0.573) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 5 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 5 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 5 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 5 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.491, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.440, test=-0.520) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.464, test=-0.461) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.430, test=-0.578) total time=   0.2s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.489, test=-0.378) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.440, test=-0.521) total time=   0.2s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.429, test=-0.573) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.489, test=-0.378) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.464) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.429, test=-0.573) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.440, test=-0.521) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.489, test=-0.378) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.429, test=-0.573) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.440, test=-0.521) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.489, test=-0.378) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.489, test=-0.378) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.440, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.464) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.429, test=-0.573) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.480, test=-0.519) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.492, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.514, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.469, test=-0.515) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.469) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.446, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.514, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.468) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.447, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.515, test=-0.385) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.446, test=-0.604) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.515, test=-0.385) total time=   0.6s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.446, test=-0.602) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.515, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.515) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.468) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.515, test=-0.385) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.515, test=-0.385) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.515, test=-0.385) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.515, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.468) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.515, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.468) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.515, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.515, test=-0.385) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.515, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.515, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.515, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.515, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.515, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.515, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.515) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.515, test=-0.385) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.515) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.468) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.446, test=-0.604) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.550, test=-0.406) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.508, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.524, test=-0.505) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.478, test=-0.639) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.592, test=-0.467) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.544, test=-0.613) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.567, test=-0.530) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.526, test=-0.665) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.529, test=-0.399) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.485, test=-0.529) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.501, test=-0.486) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.604) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.478, test=-0.527) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.476) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.394) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.478, test=-0.527) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.476) total time=   1.4s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.456, test=-0.603) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.394) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.478, test=-0.527) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.476) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.478, test=-0.527) total time=   0.2s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.476) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.456, test=-0.603) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.394) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.478, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.476) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.478, test=-0.527) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.476) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.456, test=-0.603) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.478, test=-0.527) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.476) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.603) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.478, test=-0.527) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.476) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.456, test=-0.603) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.478, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.476) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.478, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.476) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.456, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.478, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.476) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.478, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.476) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.456, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.478, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.476) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.478, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.476) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.456, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.478, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.476) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.478, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.476) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.456, test=-0.603) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.478, test=-0.527) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.476) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.456, test=-0.603) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.527, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.483, test=-0.520) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.475) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.610) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.472) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.450, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.476, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.451, test=-0.607) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.388) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.388) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.476, test=-0.517) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.471) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.450, test=-0.608) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.494, test=-0.471) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.451, test=-0.608) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.388) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.476, test=-0.516) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.494, test=-0.471) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.451, test=-0.608) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.550, test=-0.406) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.508, test=-0.538) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.487) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.477, test=-0.638) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.600, test=-0.472) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.552, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.574, test=-0.534) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.533, test=-0.672) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.534, test=-0.402) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.490, test=-0.533) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.504, test=-0.487) total time=   0.4s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.609) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.486, test=-0.532) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.486, test=-0.532) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.501, test=-0.481) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=0.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.462, test=-0.609) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.530, test=-0.396) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.486, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.500, test=-0.477) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.461, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.498, test=-0.475) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.391) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.519) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.499, test=-0.475) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.455, test=-0.611) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.612) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.518) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.499, test=-0.474) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.612) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.390) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.518) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.499, test=-0.474) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.612) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.525, test=-0.390) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.499, test=-0.474) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.518) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.499, test=-0.474) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.454, test=-0.612) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.525, test=-0.390) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.518) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.499, test=-0.474) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.454, test=-0.612) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.550, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.507, test=-0.539) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.521, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.477, test=-0.637) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.607, test=-0.479) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.560, test=-0.622) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.582, test=-0.540) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.679) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.407) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.489) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.615) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.405) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.495, test=-0.538) total time=   0.2s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.486) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.616) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.495, test=-0.538) total time=   0.5s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.486) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.616) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.486) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.616) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.405) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.405) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.616) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.405) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.495, test=-0.538) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.405) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.495, test=-0.538) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.486) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.616) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.405) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.495, test=-0.538) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.470, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.532, test=-0.397) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.489, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.503, test=-0.477) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.614) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.616) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.530, test=-0.393) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.458, test=-0.615) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.503, test=-0.478) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.616) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.530, test=-0.393) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.521) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.458, test=-0.616) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.616) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.530, test=-0.393) total time=   0.3s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.530, test=-0.393) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.503, test=-0.478) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.530, test=-0.393) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.503, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.458, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.550, test=-0.408) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.507, test=-0.540) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.521, test=-0.486) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.477, test=-0.635) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.617, test=-0.487) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.570, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.591, test=-0.547) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.548, test=-0.687) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.549, test=-0.415) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.548) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.493) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.479, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.549, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.548) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.479, test=-0.624) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.549, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.548) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.479, test=-0.624) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.549, test=-0.415) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.548) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.479, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.549, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.548) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.479, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.549, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.548) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.479, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.549, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.548) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.479, test=-0.624) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.549, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.548) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.479, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.549, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.548) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.492) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.479, test=-0.624) total time=   0.3s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.549, test=-0.415) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.548) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.479, test=-0.624) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.549, test=-0.415) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.548) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.492) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.479, test=-0.624) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.549, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.548) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.492) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.479, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.549, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.548) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.479, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.549, test=-0.415) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.548) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.479, test=-0.624) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.549, test=-0.415) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.548) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.492) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.479, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.549, test=-0.415) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.548) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.492) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.479, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.549, test=-0.415) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.548) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.520, test=-0.492) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.479, test=-0.624) total time=   0.2s\n",
      "[CV 1/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.549, test=-0.415) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.548) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.520, test=-0.492) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.479, test=-0.624) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.533, test=-0.397) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.490, test=-0.523) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.462, test=-0.615) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.394) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.521) total time=   0.4s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.504, test=-0.479) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.617) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.504, test=-0.479) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.615) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.617) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.504, test=-0.478) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.617) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.504, test=-0.478) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.617) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.521) total time=   0.4s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.504, test=-0.478) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.617) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.521) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.521) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.504, test=-0.478) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.394) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.521) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.531, test=-0.394) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.488, test=-0.521) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.504, test=-0.478) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.459, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.550, test=-0.409) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.515, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.521, test=-0.486) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.478, test=-0.635) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.620, test=-0.490) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.573, test=-0.632) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.594, test=-0.549) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.551, test=-0.689) total time=   0.3s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.418) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.552) total time=   0.2s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.495) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.627) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.495) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.627) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.418) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.495) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.627) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.418) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.552) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.495) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.627) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.495) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.627) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.495) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.627) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.495) total time=   0.3s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.627) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.495) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.627) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.552) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.495) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.627) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.495) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.627) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.418) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.552) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.495) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.627) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.418) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.495) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.627) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.552) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.495) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.627) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.495) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.627) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.418) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.552) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.495) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.627) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.552) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.495) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.627) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.418) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.509, test=-0.552) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.523, test=-0.495) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.482, test=-0.627) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.509, test=-0.552) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.523, test=-0.495) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=1.7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.482, test=-0.627) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.534, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.491, test=-0.523) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.506, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.463, test=-0.616) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.532, test=-0.395) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.490, test=-0.522) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.480) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.460, test=-0.618) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.533, test=-0.395) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.490, test=-0.522) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.479) total time=   0.3s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.617) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.532, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.490, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.460, test=-0.618) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.532, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.490, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.479) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.618) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.532, test=-0.395) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.490, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.479) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.460, test=-0.618) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.532, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.490, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.618) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.532, test=-0.395) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.490, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.479) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.460, test=-0.618) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.532, test=-0.395) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.490, test=-0.522) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.479) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.618) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.532, test=-0.395) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.490, test=-0.522) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.479) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.460, test=-0.618) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.532, test=-0.395) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.490, test=-0.522) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.479) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.618) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.532, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.490, test=-0.522) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.460, test=-0.618) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.532, test=-0.395) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.490, test=-0.522) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.618) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.532, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.490, test=-0.522) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.460, test=-0.618) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.532, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.490, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.618) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.532, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.490, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.460, test=-0.618) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.532, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.490, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.618) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.532, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.490, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.460, test=-0.618) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.532, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.490, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.505, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.460, test=-0.618) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.532, test=-0.395) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.490, test=-0.522) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.505, test=-0.479) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.460, test=-0.618) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.560, test=-0.418) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.517, test=-0.554) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.531, test=-0.495) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.488, test=-0.642) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.624, test=-0.494) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.578, test=-0.636) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.599, test=-0.553) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.555, test=-0.693) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.558, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.514, test=-0.557) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.499) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.631) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.557, test=-0.423) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.514, test=-0.557) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.498) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.631) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.514, test=-0.557) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.498) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.631) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.514, test=-0.557) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.498) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.631) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.514, test=-0.557) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.498) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.631) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.557, test=-0.423) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.514, test=-0.557) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.498) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.631) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.514, test=-0.557) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.498) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.631) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.557, test=-0.423) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.514, test=-0.557) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.498) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.631) total time=   0.2s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.514, test=-0.557) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.498) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.631) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.514, test=-0.557) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.498) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.631) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.514, test=-0.557) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.498) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.631) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.514, test=-0.557) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.498) total time=   0.3s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.631) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.557, test=-0.423) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.514, test=-0.557) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.498) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.631) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.557, test=-0.423) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.514, test=-0.557) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.498) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.631) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.514, test=-0.557) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.498) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.631) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.514, test=-0.557) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.498) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.631) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.514, test=-0.557) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.498) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.487, test=-0.631) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.557, test=-0.423) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.514, test=-0.557) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.498) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=2, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.487, test=-0.631) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.483) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.620) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.398) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.464, test=-0.622) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.495, test=-0.525) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.510, test=-0.483) total time=   0.3s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.464, test=-0.621) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.398) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.510, test=-0.483) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.464, test=-0.622) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.398) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.510, test=-0.483) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.464, test=-0.622) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.398) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.398) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.2s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.464, test=-0.622) total time=   0.6s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.398) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.464, test=-0.622) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.398) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.510, test=-0.483) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.464, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.582, test=-0.445) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.582) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.555, test=-0.514) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.657) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.655, test=-0.526) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.609, test=-0.667) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.630, test=-0.580) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.586, test=-0.721) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.554, test=-0.603) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.571, test=-0.531) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.667) total time=   0.4s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.598, test=-0.467) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.571, test=-0.531) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.667) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.598, test=-0.467) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.554, test=-0.603) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.571, test=-0.531) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.667) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.598, test=-0.467) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.598, test=-0.467) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.598, test=-0.467) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.554, test=-0.603) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.598, test=-0.467) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.554, test=-0.603) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.571, test=-0.531) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.528, test=-0.667) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.598, test=-0.467) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.554, test=-0.603) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.571, test=-0.531) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=5, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.528, test=-0.667) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.526) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.621) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.399) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.511, test=-0.484) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.399) total time=   0.8s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.399) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.399) total time=   0.6s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.484) total time=   0.4s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.399) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.484) total time=   0.8s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   1.3s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.5s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.511, test=-0.484) total time=   0.5s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.496, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.511, test=-0.484) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.538, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.496, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.511, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.591, test=-0.455) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.546, test=-0.592) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.564, test=-0.522) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.519, test=-0.664) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.664, test=-0.535) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.618, test=-0.676) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.640, test=-0.588) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.595, test=-0.729) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.611, test=-0.480) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.541, test=-0.678) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.611, test=-0.480) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.566, test=-0.617) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.584, test=-0.542) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.611, test=-0.480) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.566, test=-0.617) total time=   0.8s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.584, test=-0.542) total time=   0.7s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.541, test=-0.678) total time=   0.2s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.566, test=-0.617) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.584, test=-0.542) total time=   0.5s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.541, test=-0.678) total time=   0.5s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.611, test=-0.480) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.566, test=-0.617) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.541, test=-0.678) total time=   0.6s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.611, test=-0.480) total time=   0.8s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.566, test=-0.617) total time=   0.8s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.584, test=-0.542) total time=   0.3s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.541, test=-0.678) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.611, test=-0.480) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.566, test=-0.617) total time=   0.7s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.584, test=-0.542) total time=   0.6s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.541, test=-0.678) total time=   0.2s\n",
      "[CV 1/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.611, test=-0.480) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.566, test=-0.617) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.584, test=-0.542) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=6, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.541, test=-0.678) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.3s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.465, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.599, test=-0.465) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.555, test=-0.602) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.573, test=-0.530) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.529, test=-0.671) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.672, test=-0.544) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.626, test=-0.685) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.648, test=-0.596) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.604, test=-0.737) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.622, test=-0.492) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.578, test=-0.630) total time=   0.3s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.689) total time=   0.2s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.622, test=-0.492) total time=   0.5s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.578, test=-0.630) total time=   0.2s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.689) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.689) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.689) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.622, test=-0.492) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.622, test=-0.492) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.578, test=-0.630) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.596, test=-0.552) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=7, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.553, test=-0.689) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.622) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.2s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.2s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.539, test=-0.399) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.539, test=-0.399) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.525) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.484) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.608, test=-0.475) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.564, test=-0.613) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.583, test=-0.538) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.538, test=-0.679) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.680, test=-0.553) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.634, test=-0.694) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.657, test=-0.604) total time=   0.3s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.612, test=-0.744) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.589, test=-0.643) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.608, test=-0.562) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.564, test=-0.699) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.589, test=-0.643) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.608, test=-0.562) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.564, test=-0.699) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.589, test=-0.643) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.608, test=-0.562) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.564, test=-0.699) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.589, test=-0.643) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.608, test=-0.562) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.564, test=-0.699) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.589, test=-0.643) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.608, test=-0.562) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.564, test=-0.699) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.589, test=-0.643) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.608, test=-0.562) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.564, test=-0.699) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.589, test=-0.643) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.608, test=-0.562) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.564, test=-0.699) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.634, test=-0.504) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.589, test=-0.643) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.608, test=-0.562) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.564, test=-0.699) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.589, test=-0.643) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.608, test=-0.562) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.564, test=-0.699) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.634, test=-0.504) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.589, test=-0.643) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.608, test=-0.562) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.564, test=-0.699) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.589, test=-0.643) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.608, test=-0.562) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.564, test=-0.699) total time=   0.2s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.589, test=-0.643) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.608, test=-0.562) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.564, test=-0.699) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.589, test=-0.643) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.608, test=-0.562) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.564, test=-0.699) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.634, test=-0.504) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.589, test=-0.643) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.608, test=-0.562) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.564, test=-0.699) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.634, test=-0.504) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.589, test=-0.643) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.608, test=-0.562) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.564, test=-0.699) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.634, test=-0.504) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.589, test=-0.643) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.608, test=-0.562) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.564, test=-0.699) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.634, test=-0.504) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.589, test=-0.643) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.608, test=-0.562) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.564, test=-0.699) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.634, test=-0.504) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.589, test=-0.643) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.608, test=-0.562) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=8, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.564, test=-0.699) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.622) total time=   0.2s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.526) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.9s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.497, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.497, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.617, test=-0.485) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.573, test=-0.623) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.592, test=-0.546) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.547, test=-0.687) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.688, test=-0.561) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.642, test=-0.702) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.665, test=-0.611) total time=   0.3s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.620, test=-0.752) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.644, test=-0.515) total time=   0.3s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.619, test=-0.572) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.575, test=-0.709) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.644, test=-0.515) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.600, test=-0.654) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.575, test=-0.709) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.600, test=-0.654) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.644, test=-0.515) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.600, test=-0.654) total time=   0.2s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.644, test=-0.515) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.619, test=-0.572) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.644, test=-0.515) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.600, test=-0.654) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.619, test=-0.572) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=9, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.575, test=-0.709) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.498, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.498, test=-0.526) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.2s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.624) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.4s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.498, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.623) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.498, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.498, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.498, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.498, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.498, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.624) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.498, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.624) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.498, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.498, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.624) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.498, test=-0.526) total time=   0.3s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.3s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.624) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.498, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.8s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.624) total time=   1.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.498, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.498, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.498, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.498, test=-0.526) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.498, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.498, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.512, test=-0.485) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.466, test=-0.624) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.540, test=-0.400) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.498, test=-0.526) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.512, test=-0.485) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=True, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.466, test=-0.624) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.626, test=-0.495) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.582, test=-0.633) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.602, test=-0.554) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=lbfgs;, score=(train=-0.557, test=-0.695) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.695, test=-0.569) total time=   0.2s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.650, test=-0.710) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.673, test=-0.618) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:431: ConvergenceWarning: Newton solver did not converge after 1 iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=1, estimator__solver=newton-cholesky;, score=(train=-0.628, test=-0.759) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.655, test=-0.526) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.610, test=-0.666) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.630, test=-0.581) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=lbfgs;, score=(train=-0.586, test=-0.719) total time=   0.5s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.655, test=-0.526) total time=   0.5s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=5, estimator__solver=newton-cholesky;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=lbfgs;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=10, estimator__solver=newton-cholesky;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=lbfgs;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.655, test=-0.526) total time=   0.1s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=20, estimator__solver=newton-cholesky;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=lbfgs;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.630, test=-0.581) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=30, estimator__solver=newton-cholesky;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=lbfgs;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=50, estimator__solver=newton-cholesky;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=lbfgs;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.610, test=-0.666) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=100, estimator__solver=newton-cholesky;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.630, test=-0.581) total time=   0.1s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=lbfgs;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=150, estimator__solver=newton-cholesky;, score=(train=-0.586, test=-0.719) total time=   0.1s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=lbfgs;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=200, estimator__solver=newton-cholesky;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.610, test=-0.666) total time=   0.0s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=lbfgs;, score=(train=-0.586, test=-0.719) total time=   0.0s\n",
      "[CV 1/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.655, test=-0.526) total time=   0.0s\n",
      "[CV 2/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.610, test=-0.666) total time=   0.1s\n",
      "[CV 3/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.630, test=-0.581) total time=   0.0s\n",
      "[CV 4/4] END estimator__alpha=10, estimator__fit_intercept=False, estimator__max_iter=250, estimator__solver=newton-cholesky;, score=(train=-0.586, test=-0.719) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, error_score=&#x27;raise&#x27;,\n",
       "             estimator=MultiOutputRegressor(estimator=PoissonRegressor()),\n",
       "             param_grid={&#x27;estimator__alpha&#x27;: [0, 0.1, 0.5, 0.7, 1, 1.5, 1.7, 2,\n",
       "                                              5, 6, 7, 8, 9, 10],\n",
       "                         &#x27;estimator__fit_intercept&#x27;: [True, False],\n",
       "                         &#x27;estimator__max_iter&#x27;: [1, 5, 10, 20, 30, 50, 100, 150,\n",
       "                                                 200, 250],\n",
       "                         &#x27;estimator__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cholesky&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "             verbose=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4, error_score=&#x27;raise&#x27;,\n",
       "             estimator=MultiOutputRegressor(estimator=PoissonRegressor()),\n",
       "             param_grid={&#x27;estimator__alpha&#x27;: [0, 0.1, 0.5, 0.7, 1, 1.5, 1.7, 2,\n",
       "                                              5, 6, 7, 8, 9, 10],\n",
       "                         &#x27;estimator__fit_intercept&#x27;: [True, False],\n",
       "                         &#x27;estimator__max_iter&#x27;: [1, 5, 10, 20, 30, 50, 100, 150,\n",
       "                                                 200, 250],\n",
       "                         &#x27;estimator__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cholesky&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "             verbose=7)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: MultiOutputRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultiOutputRegressor(estimator=PoissonRegressor(alpha=0.1, max_iter=10))</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: PoissonRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>PoissonRegressor(alpha=0.1, max_iter=10)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PoissonRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.PoissonRegressor.html\">?<span>Documentation for PoissonRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>PoissonRegressor(alpha=0.1, max_iter=10)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "             estimator=MultiOutputRegressor(estimator=PoissonRegressor()),\n",
       "             param_grid={'estimator__alpha': [0, 0.1, 0.5, 0.7, 1, 1.5, 1.7, 2,\n",
       "                                              5, 6, 7, 8, 9, 10],\n",
       "                         'estimator__fit_intercept': [True, False],\n",
       "                         'estimator__max_iter': [1, 5, 10, 20, 30, 50, 100, 150,\n",
       "                                                 200, 250],\n",
       "                         'estimator__solver': ['lbfgs', 'newton-cholesky']},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error',\n",
       "             verbose=7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor \n",
    "#tuning poisson \n",
    "poisson = PoissonRegressor()\n",
    "grid_params4 = {\n",
    "    \"estimator__alpha\": [0,0.1, 0.5, 0.7, 1, 1.5, 1.7, 2, 5,6,7,8,9,10,],\n",
    "    \"estimator__fit_intercept\" : [True, False],\n",
    "    \"estimator__solver\": [\"lbfgs\", \"newton-cholesky\"],\n",
    "    \"estimator__max_iter\": [1,5,10,20,30,50,100,150,200,250],\n",
    "\n",
    "}\n",
    "multipoisson = MultiOutputRegressor(poisson)\n",
    "bestmulti = GridSearchCV(multipoisson, grid_params4,scoring=\"neg_mean_squared_error\", cv=4, refit=True, verbose=7, return_train_score=True, error_score='raise')\n",
    "bestmulti.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f262f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative mean squared errors in training data \n",
      "Random Forest Regressor -0.5012144813588587\n",
      "Ridge Regression -0.4845313681391752\n",
      "K Nearest Regressor -0.4911107783434826\n",
      "Poisson Regression  -0.4808091461618781\n"
     ]
    }
   ],
   "source": [
    "print(\"Negative mean squared errors in training data \")\n",
    "print(f\"Random Forest Regressor {rancv.best_score_}\")\n",
    "print(f\"Ridge Regression {ridgecvval.best_score_}\")\n",
    "print(f\"K Nearest Regressor {knncv.best_score_}\")\n",
    "print(\"Poisson Regression \", bestmulti.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea7dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing each model on testing data\n",
      "MSE Scores after training each model\n",
      "Random forest  0.5148135251437415\n",
      "Ridge regression  0.5182689299222764\n",
      "K nearest neighbour regressor  0.5507617051013278\n",
      "Poisson regression  0.5234404893970696\n",
      "MAE Scores after training each model\n",
      "Random forest  0.344820874044183\n",
      "Ridge regression  0.3376033576376883\n",
      "K nearest neighbour regressor  0.35408805031446544\n",
      "Poisson regression  0.339436208491819\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing each model on testing data\")\n",
    "\n",
    "bestran = rancv.best_estimator_\n",
    "bestknn = knncv.best_estimator_\n",
    "bestpoisson = bestmulti.best_estimator_\n",
    "\n",
    "y1pred = bestran.predict(X_test)\n",
    "y2pred = ridgecvval.predict(X_test)\n",
    "y3pred = bestknn.predict(X_test)\n",
    "y4pred = bestpoisson.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "print(\"MSE Scores after training each model\")\n",
    "print(\"Random forest \",mean_squared_error(y_test,y1pred))\n",
    "print(\"Ridge regression \",mean_squared_error(y_test,y2pred))\n",
    "print(\"K nearest neighbour regressor \",mean_squared_error(y_test,y3pred))\n",
    "print(\"Poisson regression \" ,mean_squared_error(y_test,y4pred))\n",
    "\n",
    "print(\"MAE Scores after training each model\")\n",
    "print(\"Random forest \",mean_absolute_error(y_test,y1pred))\n",
    "print(\"Ridge regression \",mean_absolute_error(y_test,y2pred))\n",
    "print(\"K nearest neighbour regressor \",mean_absolute_error(y_test,y3pred))\n",
    "print(\"Poisson regression \" ,mean_absolute_error(y_test,y4pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d046f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poisson_model.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "joblib.dump(bestpoisson, \"poisson_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20828ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
